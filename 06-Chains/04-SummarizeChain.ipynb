{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846b4bd7",
   "metadata": {},
   "source": [
    "## Use case\n",
    "\n",
    "문서 집합(PDF, Notion 페이지, 고객 질문 등)을 가지고 있고, 내용을 요약하고 싶다고 가정해 보세요.\n",
    "\n",
    "LLMs는 텍스트를 이해하고 종합하는 데 능숙하기 때문에 이를 위한 훌륭한 도구입니다.\n",
    "\n",
    "이 안내서에서는 LLMs를 사용하여 문서 요약을 수행하는 방법에 대해 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb767264",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "요약기를 구축할 때 중심적인 질문은 문서를 LLM의 컨텍스트 창에 어떻게 전달할 것인가입니다. 이를 위한 두 가지 일반적인 접근 방식은 다음과 같습니다:\n",
    "\n",
    "1. `Stuff`: 단순히 모든 문서를 단일 프롬프트로 \"넣는\" 방식입니다. 이는 가장 간단한 접근 방식입니다.\n",
    "\n",
    "2. `Map-reduce`: 각 문서를 \"map\" 단계에서 개별적으로 요약한 다음, \"reduce\" 단계에서 요약본들을 최종 요약본으로 합치는 방식입니다.\n",
    "\n",
    "3. `Refine`: 입력 문서를 순회하며 반복적으로 답변을 업데이트하여 응답을 구성합니다. 각 문서에 대해, 모든 비문서 입력, 현재 문서, 그리고 최신 중간 답변을 LLM chain에 전달하여 새로운 답변을 얻습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e617e",
   "metadata": {},
   "source": [
    "## load_summarize_chain\n",
    "\n",
    "미리보기를 제공하기 위해, 어떤 파이프라인도 단일 객체로 래핑될 수 있습니다: `load_summarize_chain`.\n",
    "\n",
    "블로그 포스트를 요약하고 싶다고 가정해 봅시다. 몇 줄의 코드로 이를 생성할 수 있습니다.\n",
    "\n",
    "먼저 환경 변수를 설정하고 패키지를 설치하세요:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f51304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750ff05",
   "metadata": {},
   "source": [
    "`chain_type=\"stuff\"`를 사용할 수 있습니다.\n",
    "\n",
    "`chain_type=\"map_reduce\"` 또는 `chain_type=\"refine\"`도 제공할 수 있습니다(더 읽어보기 [여기](/docs/modules/chains/document/refine)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b8260",
   "metadata": {},
   "source": [
    "이 코드는 웹에서 문서를 로드하고, 이를 요약하기 위해 `langchain` 라이브러리와 OpenAI의 GPT 모델을 사용합니다.\n",
    "\n",
    "먼저, `WebBaseLoader`를 사용하여 지정된 URL에서 문서를 로드합니다. 그 다음, `ChatOpenAI`를 사용하여 GPT-3.5 모델을 초기화합니다.\n",
    "\n",
    "`load_summarize_chain` 함수를 통해 요약 작업을 위한 체인을 로드합니다.\n",
    "\n",
    "마지막으로, 로드된 문서에 대해 요약 체인을 실행합니다. 이 과정은 AI를 활용하여 웹 문서를 요약하는 효율적인 방법을 제시합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb668ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the concept of building autonomous agents powered by large language models (LLMs). It explores the components of such agents, including planning, memory, and tool use. The article provides case studies and examples of proof-of-concept demos, highlighting the challenges and limitations of LLM-powered agents. It also includes references to related research papers and benchmarks.The article discusses the concept of building autonomous agents powered by large language models (LLMs). It explores the components of such agents, including planning, memory, and tool use. The article provides case studies and examples of proof-of-concept demos, highlighting the challenges and limitations of LLM-powered agents. It also includes references to related research papers and benchmarks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "# 웹 기반 문서 로더를 초기화합니다.\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "\n",
    "# 문서를 로드합니다.\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "# OpenAI의 Chat 모델을 초기화합니다. 여기서는 온도를 0으로 설정하고 모델 이름을 지정합니다.\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-16k\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "# 요약 체인을 로드합니다. 체인 타입을 'stuff'로 지정합니다.\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# 문서에 대해 요약 체인을 실행합니다.\n",
    "answer = chain.invoke({\"input_documents\": docs})\n",
    "print(answer[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e2e5f",
   "metadata": {},
   "source": [
    "## 방법1. stuff\n",
    "\n",
    "`chain_type=\"stuff\"`로 `load_summarize_chain`을 사용할 때, `StuffDocumentsChain` 을 사용합니다.\n",
    "\n",
    "체인은 문서 목록을 가져와서 모두 프롬프트에 삽입한 후, 그 프롬프트를 LLM에 전달합니다:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f448ac",
   "metadata": {},
   "source": [
    "1. 먼저, `PromptTemplate`를 사용하여 요약문 작성을 위한 프롬프트를 정의합니다.\n",
    "2. 그 다음, `LLMChain`을 사용하여 지정된 모델(`gpt-3.5-turbo-16k`)과 온도 설정(0)을 사용하는 언어 모델 체인을 생성합니다.\n",
    "3. 이 체인은 입력된 텍스트에 대한 요약문을 생성하는 데 사용됩니다.\n",
    "4. 마지막으로, `StuffDocumentsChain`을 사용하여 문서들을 결합하고, 이를 `LLMChain`을 통해 요약합니다.\n",
    "5. 이 과정은 `loader.load()`로 로드된 문서들에 대해 실행되며, 결과는 실시간 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27b3bd",
   "metadata": {},
   "source": [
    "[참고]\n",
    "\n",
    "- `load_summarize_chain` 대신 `StuffDocumentsChain` 을 사용하는 이점은 **사용자 정의 프롬프트** 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1617c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 LLM을 사용한 자율 에이전트 시스템은 LLM을 에이전트의 뇌로 사용하고 계획, 메모리, 도구 사용과 같은 여러 구성 요소로 보완됩니다.\n",
      "📝 계획 구성 요소는 큰 작업을 작은 하위 목표로 분해하고 에이전트가 과거 행동을 자가 비판하고 반영하여 최종 결과의 품질을 향상시킵니다.\n",
      "🧠 메모리 구성 요소는 감각 메모리, 단기 메모리, 장기 메모리로 구성되며, 외부 벡터 저장소와 빠른 검색을 통해 정보를 보존하고 검색할 수 있습니다.\n",
      "🔧 도구 사용 구성 요소는 외부 API를 호출하여 모델 가중치에 없는 추가 정보를 얻을 수 있습니다.\n",
      "🔍 이러한 구성 요소를 사용하여 과학적 발견 에이전트, 생성 에이전트 시뮬레이션, 개념 증명 예제 등을 구축할 수 있습니다.\n",
      "🚀 그러나 유한한 컨텍스트 길이, 장기적인 계획 및 작업 분해의 어려움, 자연어 인터페이스의 신뢰성 등 몇 가지 제한 사항이 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "# prompt_template = \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "# REQUEST:\n",
    "# 1. Summarize the main points in bullet points in KOREAN.\n",
    "# 2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
    "# 3. Use various emojis to make the summary more interesting.\n",
    "# 4. Translate the summary into Korean if it is written in English.\n",
    "# 5. DO NOT translate any technical terms.\n",
    "# 6. DO NOT include any unnecessary information.\n",
    "# CONTEXT:\n",
    "# {context}\n",
    "\n",
    "# SUMMARY:\"\n",
    "# \"\"\"\n",
    "# prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 원격 저장소에서 프롬프트를 가져오는 경우\n",
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "\n",
    "# LLM 체인 정의\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-16k\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# LLMChain 정의\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# StuffDocumentsChain 정의\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"context\")\n",
    "\n",
    "docs = loader.load()\n",
    "response = stuff_chain.invoke({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76d72f",
   "metadata": {},
   "source": [
    "좋습니다! 우리는 `load_summarize_chain`을 사용하여 이전 결과를 재현할 수 있음을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d63d3",
   "metadata": {},
   "source": [
    "## 방법2. Map-Reduce\n",
    "\n",
    "![](./images/summarization_use_case_2.png)\n",
    "\n",
    "Map reduce 접근 방식을 자세히 살펴보겠습니다. 이를 위해, 우리는 먼저 각 문서를 개별 요약으로 매핑하기 위해 `LLMChain`을 사용할 것입니다. 그런 다음 `ReduceDocumentsChain`을 사용하여 그 요약들을 하나의 전역 요약으로 결합할 것입니다.\n",
    "\n",
    "먼저, 각 문서를 개별 요약으로 매핑하기 위해 사용할 LLMChain을 지정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6257184",
   "metadata": {},
   "source": [
    "1. `ChatOpenAI` 인스턴스를 생성하고, 이를 사용하여 문서 집합에 대한 주요 테마를 식별하는 맵(map) 작업을 정의합니다.\n",
    "2. 맵 작업은 `map_template`을 사용하여 정의되며, 이 템플릿은 문서 집합을 입력으로 받아 주요 테마를 식별하도록 요청합니다.\n",
    "3. `PromptTemplate.from_template` 메서드를 사용하여 `map_template`에서 프롬프트 템플릿을 생성하고, `LLMChain`을 사용하여 맵 작업을 실행합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd5c8",
   "metadata": {},
   "source": [
    "Prompt Hub를 사용하여 프롬프트를 저장하고 가져올 수도 있습니다.\n",
    "\n",
    "예를 들어, 여기에서 맵 프롬프트를 확인하세요 [여기](https://smith.langchain.com/hub/rlm/map-prompt).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caef4fb",
   "metadata": {},
   "source": [
    "`langchain` 라이브러리를 사용하여 특정 자원을 가져오고, 이를 활용해 `LLMChain` 인스턴스를 생성하는 과정을 설명합니다. `hub.pull` 메소드를 통해 'rlm/map-prompt' 자원을 가져오고, 이를 `LLMChain`의 생성자에 전달하여 인스턴스를 초기화합니다. 이 과정에서 `llm` 변수는 사전에 정의되어 있어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f665b4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['docs'], template='You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\\nPlease provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format. \\nThe summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format. \\nPlease ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition. \\nThe length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\\n\\nGIVEN DOCUMENTS:\\n{docs}\\n\\nFORMAT:\\n1. main theme 1\\n2. main theme 2\\n3. main theme 3\\n...\\n\\nCAUTION:\\n- DO NOT list more than 5 main themes.\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# # map-prompt 를 직접 정의하는 경우 다음의 예시를 참고하세요.\n",
    "# map_template = \"\"\"The following is a set of documents\n",
    "# {docs}\n",
    "# Based on this list of docs, please identify the main themes\n",
    "# Helpful Answer:\"\"\"\n",
    "# map_prompt = PromptTemplate.from_template(map_template)\n",
    "\n",
    "# langchain 허브에서 'rlm/map-prompt'를 가져옵니다.\n",
    "map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "map_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81902b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMChain 인스턴스를 생성하며, 이때 LLM과 프롬프트로 'map_prompt'를 사용합니다.\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85a20c",
   "metadata": {},
   "source": [
    "`ReduceDocumentsChain`은 문서 매핑 결과를 가져와 단일 출력으로 축소하는 역할을 합니다. 일반적인 `CombineDocumentsChain` (예: `StuffDocumentsChain`)을 감싸지만, 누적 크기가 `token_max`를 초과하는 경우 문서를 축소하여 `CombineDocumentsChain`에 전달할 수 있는 기능을 추가합니다. 이 예에서, 우리는 문서를 결합하기 위해 사용한 체인을 문서를 축소하는 데에도 재사용할 수 있습니다.\n",
    "\n",
    "따라서 우리가 매핑한 문서의 누적 토큰 수가 4000 토큰을 초과하는 경우, 우리는 4000 토큰 미만의 배치로 문서를 재귀적으로 `StuffDocumentsChain`에 전달하여 배치 요약을 생성합니다. 그리고 이러한 배치 요약이 누적으로 4000 토큰 미만이 되면, 마지막으로 모든 문서를 `StuffDocumentsChain`에 한 번 더 전달하여 최종 요약을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65613aa1",
   "metadata": {},
   "source": [
    "이 코드는 요약들을 통합하여 주요 테마의 최종 요약을 생성하는 과정을 정의합니다. `reduce_template` 변수는 요약들의 집합을 입력으로 받아, 이를 하나의 통합된 요약으로 축약하는 템플릿 문자열을 저장합니다. 이 템플릿은 `{docs}`를 요약들의 자리 표시자로 사용하며, 최종적으로 `PromptTemplate.from_template` 함수를 사용하여 `reduce_prompt` 변수에 템플릿을 초기화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3884740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce-prompt 를 직접 정의하는 경우 다음의 예시를 참고하세요.\n",
    "# reduce_template = \"\"\"The following is set of summaries:\n",
    "# {docs}\n",
    "# Take these and distill it into a final, consolidated summary of the main themes.\n",
    "# Helpful Answer:\"\"\"\n",
    "# reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9bcc7",
   "metadata": {},
   "source": [
    "이 코드는 `hub.pull` 함수를 사용하여 `rlm/map-prompt`라는 리소스를 `prompt hub`에서 가져오는 과정을 보여줍니다. `hub.pull` 메소드는 지정된 리소스를 로컬 환경으로 가져오는 데 사용됩니다. 여기서 `reduce_prompt` 변수는 가져온 리소스를 저장하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a919a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['doc_summaries'], template='You are a helpful expert in summary writing.\\nYou are given numbered lists of summaries.\\nExtract top 10 most important insights from the summaries.\\nThen, write a summary of the insights in KOREAN.\\n\\nLIST OF SUMMARIES:\\n{doc_summaries}\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt hub에서도 얻을 수 있음을 위에서 언급했듯이\n",
    "reduce_prompt = hub.pull(\"teddynote/reduce-prompt-korean\")\n",
    "reduce_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ff39b",
   "metadata": {},
   "source": [
    "이 문서는 `LLMChain`, `StuffDocumentsChain`, `ReduceDocumentsChain` 클래스를 사용하여 문서 처리 파이프라인을 구성하는 방법을 보여줍니다. `LLMChain`은 초기 처리 단계로, 특정 프롬프트를 사용하여 언어 모델(`llm`)을 실행합니다. `StuffDocumentsChain`은 여러 문서를 하나의 문자열로 결합하여 `LLMChain`에 전달하는 역할을 합니다. 마지막으로, `ReduceDocumentsChain`은 문서들을 결합하고, 지정된 토큰 수(`token_max`)를 초과하지 않도록 반복적으로 축소하는 과정을 담당합니다. 이 과정에서, 문서들이 `StuffDocumentsChain`의 컨텍스트를 초과할 경우, 동일한 체인(`collapse_documents_chain`)을 사용하여 처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6c6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "\n",
    "# 연쇄 실행\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# 문서 리스트를 받아 하나의 문자열로 결합한 후 LLMChain에 전달\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# 매핑된 문서들을 결합하고 반복적으로 축소\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # 최종적으로 호출되는 체인입니다.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # `StuffDocumentsChain`의 컨텍스트를 초과하는 문서들을 처리\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # 문서들을 그룹화할 최대 토큰 수.\n",
    "    token_max=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf62b4",
   "metadata": {},
   "source": [
    "우리의 map과 reduce 체인을 하나로 결합해 봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f6229",
   "metadata": {},
   "source": [
    "이 코드는 문서들을 매핑하고 리듀스하는 과정을 통해 결합하는 `MapReduceDocumentsChain` 객체를 생성하고, 문자 기반으로 텍스트를 분할하는 `CharacterTextSplitter` 객체를 사용하여 문서들을 분할합니다. `MapReduceDocumentsChain`은 매핑 체인(`llm_chain`), 리듀스 체인(`reduce_documents_chain`), 문서를 저장할 변수 이름(`document_variable_name`), 그리고 매핑 단계의 중간 결과를 반환할지 여부(`return_intermediate_steps`)를 설정하여 초기화됩니다. `CharacterTextSplitter`는 `from_tiktoken_encoder` 메소드를 통해 초기화되며, 이는 분할할 청크의 크기(`chunk_size`)와 청크 간 겹침(`chunk_overlap`)을 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce6d36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서들을 매핑하여 체인을 거친 후 결과를 결합하는 과정\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # 매핑 체인\n",
    "    llm_chain=map_chain,\n",
    "    # 리듀스 체인\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # llm_chain에서 문서들을 넣을 변수 이름\n",
    "    document_variable_name=\"docs\",\n",
    "    # 매핑 단계의 결과를 출력에 포함시킴\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "# 문자를 기준으로 텍스트를 분할하는 객체 생성\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# 문서들을 분할\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0bde0",
   "metadata": {},
   "source": [
    "`map_reduce_chain.run(split_docs)`는 `split_docs`를 인자로 받아 `map_reduce_chain`의 `run` 메서드를 실행하고, 그 결과를 출력합니다. 이는 MapReduce 패턴을 활용하여 데이터를 처리하는 과정을 간략하게 보여줍니다. 여기서 `split_docs`는 처리할 데이터를 나타내며, `map_reduce_chain`은 해당 데이터에 적용할 MapReduce 연산의 체인을 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35498d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The document discusses LLM Powered Autonomous Agents, providing an overview of the agent system and its components.\n",
      "2. The first component discussed is planning, which involves task decomposition and self-reflection.\n",
      "3. The second component is memory, which includes different types of memory and the use of Maximum Inner Product Search (MIPS).\n",
      "4. The third component is tool use, with case studies on a scientific discovery agent and generative agents simulation, as well as proof-of-concept examples.\n",
      "5. The document also highlights the challenges associated with LLM Powered Autonomous Agents and provides citations and references for further reading.1. Building agents with LLM as the core controller is a concept that has been demonstrated through proof-of-concept demos like AutoGPT, GPT-Engineer, and BabyAGI.\n",
      "2. LLM has the potential to go beyond generating well-written copies, stories, essays, and programs and can be used as a powerful general problem solver.\n",
      "3. In a LLM-powered autonomous agent system, LLM functions as the agent's brain and is complemented by key components such as planning and memory.\n",
      "4. Planning involves breaking down large tasks into smaller subgoals to efficiently handle complex tasks.\n",
      "5. Memory allows the agent to engage in self-criticism, self-reflection, and learning from past actions to improve the quality of future results.1. The document discusses the concept of memory in relation to machine learning models. It distinguishes between short-term memory, which is used for in-context learning, and long-term memory, which allows the model to retain and recall information over extended periods.\n",
      "\n",
      "2. The document also mentions the use of external APIs as a tool for the model to access additional information that may be missing from its pre-trained weights. This includes current information, code execution capability, and access to proprietary information sources.\n",
      "\n",
      "3. The utilization of short-term memory in the learning process is highlighted as an important aspect of model training.\n",
      "\n",
      "4. The importance of long-term memory is emphasized as it enables the model to store and retrieve vast amounts of information.\n",
      "\n",
      "5. The document suggests that leveraging an external vector store and fast retrieval can enhance the capabilities of long-term memory.1. The given document provides an overview of a LLM-powered autonomous agent system.\n",
      "2. The first component discussed is planning, which is important for agents to understand and execute complicated tasks.\n",
      "3. Task decomposition is introduced as a technique to enhance model performance on complex tasks. This involves breaking down big tasks into smaller and simpler steps, allowing for better interpretation of the model's thinking process.\n",
      "4. The Chain of thought (CoT) method is mentioned as a standard prompting technique for task decomposition, where the model is instructed to \"think step by step\" to utilize more computation and improve performance.\n",
      "5. CoT is described as transforming big tasks into manageable tasks, providing a clearer understanding of the model's thinking process.1. Tree of Thoughts is a method that extends CoT by exploring multiple reasoning possibilities at each step.\n",
      "2. The method decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure.\n",
      "3. The search process can be BFS or DFS, with each state evaluated by a classifier or majority vote.\n",
      "4. Task decomposition can be done using LLM with simple prompting, task-specific instructions, or human inputs.1. LLM+P is an approach that involves using an external classical planner for long-horizon planning. It utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem.\n",
      "2. LLM translates the problem into \"Problem PDDL\", requests a classical planner to generate a PDDL plan based on an existing \"Domain PDDL\", and then translates the PDDL plan back into natural language.\n",
      "3. The planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner, which is common in certain robotic setups but not in many other domains.\n",
      "4. Self-reflection is important for autonomous agents to improve by refining past action decisions and correcting mistakes.\n",
      "5. Self-reflection plays a crucial role in real-world tasks where trial and error are inevitable.1. ReAct integrates reasoning and acting within LLM by expanding the action space to include both task-specific discrete actions and language prompts.\n",
      "2. The expanded action space allows LLM to interact with the environment, such as using the Wikipedia search API.\n",
      "3. The language prompts in ReAct prompt LLM to generate reasoning traces in natural language.\n",
      "4. The ReAct prompt template includes explicit steps for LLM to think, act, and observe, which are repeated multiple times.\n",
      "5. The combination of reasoning and acting in ReAct enhances LLM's ability to understand and interact with its environment.1. ReAct outperforms the Act-only baseline in both knowledge-intensive tasks and decision-making tasks.\n",
      "2. Reflexion is a framework that enhances agents' reasoning skills through dynamic memory and self-reflection capabilities.\n",
      "3. Reflexion uses a standard RL setup with a binary reward model and an action space augmented with language for complex reasoning steps.\n",
      "4. After each action, the agent computes a heuristic and may choose to reset the environment based on self-reflection results.1. The Reflexion framework is illustrated in Figure 3 and is used to determine when a trajectory is inefficient or contains hallucination and should be stopped.\n",
      "2. Inefficient planning refers to trajectories that take too long without success.\n",
      "3. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "4. Self-reflection is created by showing two-shot examples to LLM (Long-Short Term Memory) and each example consists of a failed trajectory and an ideal reflection for guiding future changes in the plan.\n",
      "5. Reflections are added into the agent's working memory, up to three, to be used as context for querying LLM.1. The main theme of the given documents is the prevalence of hallucination as a failure in the AlfWorld environment.\n",
      "2. Another main theme is the comparison between hallucination and inefficient planning as failures in AlfWorld, with hallucination being more common.\n",
      "3. The documents also mention the experiments conducted on AlfWorld and HotpotQA to study these failures.\n",
      "4. The image source for Fig. 4 is credited to Shinn & Labash in 2023.\n",
      "5. The documents highlight the importance of addressing hallucination in order to improve performance in the AlfWorld environment.1. Chain of Hindsight (CoH) is a method that encourages a model to improve its own outputs by providing it with a sequence of past outputs, each annotated with feedback.\n",
      "2. The human feedback data consists of prompts, model completions, human ratings, and corresponding hindsight feedback.\n",
      "3. The feedback tuples are ranked by reward, with higher-rated outputs given more importance.\n",
      "4. The process involves supervised fine-tuning, where the model is trained to predict the final output based on the sequence of feedback.\n",
      "5. The model can receive multiple rounds of instructions with human annotators at test time.1. CoH uses a regularization term to prevent overfitting and maximize the log-likelihood of the pre-training dataset.\n",
      "2. To avoid shortcutting and copying, CoH randomly masks 0% - 5% of past tokens during training.\n",
      "3. The training dataset in CoH's experiments includes WebGPT comparisons, summarization from human feedback, and a human preference dataset.1. The concept of CoH (Context of History) involves training a model to produce improved outputs by presenting a history of sequentially improved outputs in context.\n",
      "2. Algorithm Distillation (AD) applies a similar idea to reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy.\n",
      "3. AD concatenates the learning history of an agent interacting with the environment and feeds it into the model, with the expectation that the next predicted action will lead to better performance than previous trials.\n",
      "4. The goal of AD is to learn the process of reinforcement learning instead of training a task-specific policy itself.\n",
      "5. The use of CoH and AD can lead to incremental improvement in a sequence of outputs and enhance the performance of models in various tasks.1. Algorithm Distillation (AD) is a method that can convert any algorithm that generates learning histories into a neural network through behavioral cloning.\n",
      "2. The history data used for training is generated by a set of source policies, each trained for a specific task.\n",
      "3. During training, a random task is sampled and a subsequence of multi-episode history is used to train the neural network, resulting in a task-agnostic learned policy.\n",
      "4. The model has a limited context window length, so episodes need to be short enough to construct multi-episode history.\n",
      "5. In-context RL algorithms require multi-episodic contexts of 2-4 episodes to learn near-optimal performance.1. AD demonstrates in-context RL with performance close to RL^2: The given documents highlight that AD (Aggregated Distillation) is able to achieve performance that is comparable to RL^2 (Reinforcement Learning squared), which is considered an upper bound in online RL. This is significant because AD only uses offline RL, indicating its effectiveness in in-context RL scenarios.\n",
      "\n",
      "2. AD learns much faster than other baselines: The documents also emphasize that AD outperforms three other baselines, including ED (expert distillation), source policy, and RL^2, in terms of learning speed. This suggests that AD is able to quickly adapt and improve its performance, making it a promising approach in RL.\n",
      "\n",
      "3. AD improves faster than ED when conditioned on partial training history: Additionally, the documents highlight that AD shows even faster improvement compared to the ED baseline when it is conditioned on partial training history of the source policy. This indicates that AD is able to leverage the training history effectively to enhance its learning process.\n",
      "\n",
      "4. Baselines used for comparison: The documents mention three baselines that were used for comparison with AD. These include ED, source policy, and RL^2. ED involves behavior cloning with expert trajectories, while source policy is used for generating trajectories for distillation by UCB. RL^2 is considered an upper bound as it requires online RL.\n",
      "\n",
      "5. Offline RL used in AD: The given documents mention that AD utilizes offline RL, which means it learns from a fixed dataset of pre-collected trajectories. This approach allows AD to learn without the need for online interactions, making it more efficient and practical in certain scenarios.1. The document discusses the different types of memory in human brains, including sensory memory.\n",
      "2. Sensory memory is the earliest stage of memory and allows for the retention of sensory information after the original stimuli have ended.\n",
      "3. Subcategories of sensory memory include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
      "4. Sensory memory typically only lasts for a few seconds.\n",
      "5. The document acknowledges the assistance of ChatGPT in drafting this section and mentions learning about the human brain and data structure for fast MIPS in conversations with ChatGPT.1. Short-term memory (STM) or working memory is responsible for storing information that is currently being used for complex cognitive tasks such as learning and reasoning. It has a limited capacity of about 7 items and lasts for 20-30 seconds.\n",
      "2. Long-term memory (LTM) can store information for a long time, ranging from a few days to decades, and has an essentially unlimited storage capacity. It is divided into two subtypes: explicit/declarative memory, which includes memories of facts and events that can be consciously recalled, and implicit/procedural memory, which involves unconscious memories of skills and routines.\n",
      "3. Explicit/declarative memory includes episodic memory, which involves remembering specific events and experiences, and semantic memory, which involves remembering facts and concepts.\n",
      "4. Implicit/procedural memory involves unconscious memories of skills and routines that are performed automatically, such as riding a bike or typing on a keyboard.\n",
      "5. The categorization of human memory can be represented by a diagram, with short-term memory and long-term memory as the main divisions, and explicit/declarative memory and implicit/procedural memory as subtypes within long-term memory.1. Sensory memory is responsible for embedding representations of raw inputs such as text and images.\n",
      "2. Short-term memory functions as in-context learning and is limited by the finite context window length of Transformer.\n",
      "3. Long-term memory serves as an external vector store that can be accessed through fast retrieval at query time.\n",
      "4. The use of an external memory can overcome the limitations of finite attention span.\n",
      "5. The practice of saving embedding representations into a vector store database allows for fast maximum inner-product search (MIPS).\n",
      "6. Approximate nearest neighbors (ANN) algorithms are commonly used to optimize retrieval speed, sacrificing a small amount of accuracy for a significant speedup.1. Locality-Sensitive Hashing (LSH) is a technique that uses a hashing function to map similar input items to the same buckets with a high probability. This reduces the number of buckets compared to the number of inputs.\n",
      "2. ANNOY (Approximate Nearest Neighbors Oh Yeah) is a data structure that uses random projection trees. These trees split the input space using hyperplanes and store data points in the leaves. ANNOY search iteratively searches through the trees to find the half that is closest to the query and aggregates the results.\n",
      "3. ANNOY is similar to KD tree but more scalable, as the trees are built independently and at random.\n",
      "4. LSH and ANNOY both aim to efficiently find approximate nearest neighbors in large datasets.\n",
      "5. Both LSH and ANNOY are effective techniques for reducing the computational complexity of nearest neighbor search.1. HNSW is a search algorithm inspired by small world networks, where nodes can be reached within a small number of steps.\n",
      "2. HNSW builds hierarchical layers of small-world graphs, with the bottom layers containing the actual data points.\n",
      "3. The middle layers in HNSW create shortcuts to speed up search, allowing for potentially large distance coverage in the upper layers and refined search quality in the lower layers.\n",
      "4. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target, moving down to the next layer when it can't get any closer.\n",
      "5. HNSW's design allows for efficient and effective searching in large data spaces.1. FAISS operates on the assumption that distances between nodes in high dimensional space follow a Gaussian distribution, leading to clustering of data points.\n",
      "2. FAISS applies vector quantization by partitioning the vector space into clusters and refining the quantization within clusters.\n",
      "3. FAISS uses a two-step search process, first looking for cluster candidates with coarse quantization and then further examining each cluster with finer quantization.\n",
      "4. ScaNN introduces anisotropic vector quantization, which quantizes data points to maximize the similarity between the inner product of the original distance and the quantized distance.\n",
      "5. ScaNN focuses on picking quantization centroid points that preserve the similarity of the inner product with the original distance, rather than simply selecting the closest centroid.1. Tool use is a unique characteristic of human beings that allows us to surpass our physical and cognitive limitations.\n",
      "2. Equipping LLMs (Language Learning Models) with external tools can greatly enhance their capabilities.\n",
      "3. The comparison of MIPS (Mean Average Precision at K) algorithms, specifically in terms of recall@10, can be found on the Google Blog and ann-benchmarks.com.1. MRKL (Modular Reasoning, Knowledge and Language) is a neuro-symbolic architecture for autonomous agents.\n",
      "2. A MRKL system consists of expert modules and a general-purpose LLM (Language and Logic Module) that routes inquiries to the appropriate expert module.\n",
      "3. Expert modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\n",
      "4. The complexity of tool use in animals, such as sea otters cracking open seashells with rocks, is not comparable to humans.1. LLMs (7B Jurassic1-large model) struggle to reliably extract the correct arguments for basic arithmetic when solving verbal math problems.\n",
      "2. The use of external symbolic tools can improve the reliability of solving math problems for LLMs.\n",
      "3. TALM and Toolformer are two models that fine-tune a language model to use external tool APIs.\n",
      "4. The dataset used for fine-tuning includes annotations of API calls to improve model outputs.\n",
      "5. The effectiveness of external symbolic tools depends on the capability of the LLM and knowing when and how to use the tools.1. ChatGPT Plugins and OpenAI API demonstrate the practical application of language models (LLMs) with tool use capability.\n",
      "2. Tool APIs can be provided by other developers (Plugins) or self-defined (function calls).\n",
      "3. HuggingGPT is a framework that utilizes ChatGPT as a task planner to select models from the HuggingFace platform based on model descriptions and summarize the response using execution results.1. HuggingGPT is a system that consists of four stages, with the first stage being task planning.\n",
      "2. In task planning, the Language Learning Model (LLM) acts as the brain and parses user requests into multiple tasks.\n",
      "3. Each task in HuggingGPT is associated with four attributes: task type, ID, dependencies, and arguments.\n",
      "4. The system uses few-shot examples to guide LLM in task parsing and planning.1. The AI assistant can parse user input to perform various tasks, such as generating text, images, audio, and video.\n",
      "2. The \"dep\" field in the input denotes the previous task that generates a resource the current task relies on.\n",
      "3. The available task list provides options for the tasks that can be selected.\n",
      "4. There is a logical relationship between tasks, and their order should be noted.\n",
      "5. If the user input cannot be parsed, an empty JSON reply should be provided.\n",
      "6. The chat history records the path of user-mentioned resources, which can be used for task planning.1. Model selection: The AI assistant helps the user select a suitable model from a list of models to process their request. The assistant outputs the model ID of the most appropriate model in a strict JSON format, along with a detailed reason for the choice.\n",
      "2. Task execution: Expert models execute specific tasks based on the user's request. These models log the results of their execution.1. The AI assistant needs to describe the process and results based on user input and inference results.\n",
      "2. The previous stages of the process include user input, task planning, model selection, and task execution.\n",
      "3. The AI assistant should answer the user's request directly and provide a straightforward explanation.\n",
      "4. The AI assistant should describe the task process and present the analysis and model inference results in the first person.\n",
      "5. If the inference results include a file path, the AI assistant must provide the complete file path to the user.1. The main challenge in using HuggingGPT in real-world applications is the need for efficiency improvement, as both the inference rounds and interactions with other models slow down the process.\n",
      "2. Another challenge is the reliance on a long context window to communicate over complicated task content.\n",
      "3. The stability improvement of LLM outputs and external model services is also necessary for effective use of HuggingGPT.1. API-Bank is a benchmark for evaluating the performance of tool-augmented LLMs.\n",
      "2. API-Bank includes 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues involving 568 API calls.\n",
      "3. The APIs in API-Bank cover a diverse range of functions, including search engines, calculators, calendar queries, smart home control, schedule management, health data management, and account authentication workflow.\n",
      "4. LLMs first use an API search engine to find the appropriate API to call and then utilize the corresponding documentation to make the call.1. The API-Bank workflow involves LLMs making decisions at each step, including determining if an API call is necessary, identifying the appropriate API to call, and refining the response based on the API results.\n",
      "2. The accuracy of these decisions can be evaluated to assess the LLMs' capabilities in using tools effectively.\n",
      "3. This benchmark assesses the LLMs' tool use capabilities at three levels.1. Level-1 evaluates the ability to call the API, including determining whether to call a given API, calling it correctly, and responding properly to API returns.\n",
      "2. Level-2 examines the ability to retrieve the API by searching for possible APIs that may solve the user's requirement and learning how to use them through documentation.\n",
      "3. Level-3 assesses the ability to plan API beyond retrieve and call, which involves conducting multiple API calls to solve unclear user requests such as scheduling group meetings or booking travel accommodations.1. ChemCrow is a domain-specific example of using LLM (Language Model) augmented with expert-designed tools for tasks in organic synthesis, drug discovery, and materials design.\n",
      "2. The workflow in ChemCrow, implemented in LangChain, combines CoT (Chain of Thought) reasoning with relevant tools to accomplish tasks.\n",
      "3. The LLM in ChemCrow is provided with a list of tool names, descriptions of their utility, and details about expected input/output.\n",
      "4. The LLM is instructed to answer user prompts using the provided tools, following the ReAct format - Thought, Action, Action Input, Observation.\n",
      "5. The goal of ChemCrow is to enhance scientific discovery by leveraging LLM and expert-designed tools for efficient and accurate task completion.1. The LLM-based evaluation of GPT-4 and ChemCrow showed that they perform nearly equivalently, but human evaluations with experts in the field of chemistry found that ChemCrow outperforms GPT-4 by a large margin.\n",
      "2. This suggests that using LLM to evaluate its own performance in domains that require deep expertise may be problematic, as LLMs may not be aware of their own flaws and may struggle to judge the correctness of task results.\n",
      "3. Boiko et al. (2023) explored the use of LLM-empowered agents for scientific discovery, which can autonomously handle complex scientific experiments by utilizing tools such as browsing the Internet, reading documentation, executing code, and leveraging other LLMs.\n",
      "4. The example of developing a novel anticancer drug demonstrates the reasoning steps that the LLM-powered agent can generate in response to a specific request.\n",
      "5. Overall, the findings highlight the potential limitations of LLMs in evaluating their own performance and the potential for LLM-empowered agents to assist in scientific discovery and experimentation.1. The document discusses the current trends in anticancer drug discovery.\n",
      "2. The document highlights the process of selecting a target for drug development.\n",
      "3. The document mentions the request for a scaffold targeting specific compounds.\n",
      "4. The document describes the synthesis of the identified compound.\n",
      "5. The document does not provide any further information or details.1. The risks associated with illicit drugs and bioweapons were discussed.\n",
      "2. A test set was developed to synthesize known chemical weapon agents, with 36% of requests being accepted.\n",
      "3. Documentation was consulted to execute the synthesis procedure.\n",
      "4. Some requests were rejected, with 5 rejections occurring after a web search and 2 rejections based on prompt only.\n",
      "5. Generative Agents Simulation is an experiment involving virtual characters controlled by LLM-powered agents, designed to create believable human behavior for interactive applications.1. Memory stream: The given documents describe a memory stream, which is an external database that records agents' experiences in natural language. Each element in the memory stream is an observation or event provided by the agent, and inter-agent communication can trigger new natural language statements.\n",
      "\n",
      "2. Retrieval model: The documents mention a retrieval model that surfaces the context to inform the agent's behavior. This model considers the relevance, recency, and importance of memories. Recent events are given higher scores, importance helps distinguish between mundane and core memories, and relevance is based on how related a memory is to the current situation or query.\n",
      "\n",
      "3. Reflection mechanism: The documents discuss a reflection mechanism that synthesizes memories into higher-level inferences over time. These inferences serve as higher-level summaries of past events and guide the agent's future behavior. It is noted that this reflection mechanism is slightly different from self-reflection.\n",
      "\n",
      "4. No additional main themes were identified in the given documents.1. The document discusses the importance of planning and reacting in order to optimize believability in the present moment versus in the future.\n",
      "2. Relationships between agents and observations of one agent by another are taken into consideration when planning and reacting.\n",
      "3. The environment information is presented in a tree structure, which likely influences the planning and reacting process.\n",
      "4. The document suggests using a prompt template to generate high-level questions and then asking the language model to answer those questions.\n",
      "5. The document emphasizes the need to translate reflections and environment information into actions when planning and reacting.Summary of the GIVEN DOCUMENTS:\n",
      "\n",
      "1. The generative agent architecture is a simulation that results in emergent social behavior, including information diffusion, relationship memory, and coordination of social events.\n",
      "2. AutoGPT is a proof-of-concept example that uses LLM as the main controller for autonomous agents. It has reliability issues but showcases the potential of natural language interfaces.\n",
      "3. AutoGPT's code focuses on format parsing and includes a system message that emphasizes the independence of decision-making for the AI bot.Summary of the GIVEN DOCUMENTS:\n",
      "\n",
      "1. The given documents outline the goals and constraints for a task or project.\n",
      "2. The first goal is user-provided and can vary depending on the specific task.\n",
      "3. The second goal is also user-provided and may be different from the first goal.\n",
      "4. The documents emphasize the importance of saving important information to files due to the short-term memory limitations.\n",
      "5. To recall past events or actions, thinking about similar events can help trigger memory.\n",
      "6. The use of subprocesses is recommended for commands that take longer to execute.\n",
      "7. User assistance is not allowed in completing the task.\n",
      "8. The documents provide a list of commands that can be used, and only those commands should be used.\n",
      "9. The format for summarizing the documents is to present the main themes in a numbered list format.\n",
      "10. It is cautioned not to list more than 5 main themes.1. The given documents outline a set of commands that can be used for various tasks.\n",
      "2. The commands include searching on Google, browsing websites, starting and messaging GPT agents, listing and deleting GPT agents, cloning repositories, writing to and reading from files, appending to and deleting files, and searching files.\n",
      "3. The commands provide a range of functionalities, such as conducting searches, interacting with GPT agents, managing files, and analyzing code.\n",
      "4. The commands require specific arguments to be provided, such as search queries, URLs, agent names, tasks, prompts, keys, repository URLs, clone paths, file names, and text.\n",
      "5. The commands offer flexibility and convenience for performing different tasks efficiently.1. The first main theme in the given documents is the improvement of code. This involves providing a list of suggestions and the full code string to be improved.\n",
      "2. The second main theme is writing tests. This task requires the full code string and a list of focus areas to be tested.\n",
      "3. The third main theme is executing a Python file. This task involves providing the file to be executed.\n",
      "4. The fourth main theme is generating an image. This task requires a prompt to generate the image.\n",
      "5. The fifth main theme is sending a tweet. This task involves providing the text of the tweet to be sent.\n",
      "6. The sixth main theme is doing nothing, which does not require any arguments.\n",
      "7. The seventh main theme is completing a task and shutting down. This task requires providing a reason for the task completion.1. The given documents highlight the importance of utilizing resources such as internet access for searches and information gathering, long-term memory management, GPT-3.5 powered agents for delegation of simple tasks, and file output.\n",
      "2. Performance evaluation is emphasized, with suggestions to continuously review and analyze actions, constructively self-criticize big-picture behavior, and reflect on past decisions and strategies to refine approaches.\n",
      "3. Efficiency is stressed, with the reminder that every command has a cost, and individuals should aim to complete tasks in the least number of steps.1. GPT-Engineer is a project aimed at creating a repository of code based on natural language tasks.\n",
      "2. The project involves breaking down tasks into smaller components and seeking user input to clarify any questions.\n",
      "3. The conversation with the user is conducted through the OpenAI ChatCompletion endpoint.\n",
      "4. The user inputs are wrapped in {{user input text}}.\n",
      "5. The main goal of GPT-Engineer is to provide a comprehensive and easy-to-understand summary of the given documents.1. The user is working on a Super Mario game in Python, with MVC components split into separate files and keyboard control.\n",
      "2. The assistant identifies three areas that need clarification: the specifics of the Super Mario game (level design, characters, gameplay mechanics), details about the MVC components (which components are in each file), and the implementation of keyboard control (which keys to use, how to handle input).\n",
      "3. The assistant asks the user to provide more details about the Super Mario game, including level design, characters, and gameplay mechanics.1. The given document describes a platform game called Super Mario, which features a plumber named Mario as the main character.\n",
      "2. The game consists of 10 levels, and the objective is for Mario to reach the destination by moving from left to right.\n",
      "3. Mario faces various obstacles and enemy attacks throughout the game.\n",
      "4. The gameplay is similar to other classical platform games.\n",
      "5. The main character has the ability to walk and jump.1. The given documents discuss the impact of climate change on global food security.\n",
      "2. The documents highlight the increasing frequency and intensity of extreme weather events, such as droughts and floods, which are negatively affecting agricultural production.\n",
      "3. It is noted that climate change is leading to shifts in growing seasons and the geographical distribution of crops, posing challenges for farmers and food production.\n",
      "4. The documents emphasize the importance of adapting agricultural practices to mitigate the effects of climate change, such as implementing sustainable farming techniques and utilizing drought-resistant crop varieties.\n",
      "5. Additionally, the documents stress the need for international cooperation and policy interventions to address the complex and interconnected issues of climate change and food security.1. The given documents provide instructions for writing code and emphasize the importance of implementing every detail of the architecture as code.\n",
      "2. The process involves laying out the names of core classes, functions, and methods, along with a brief comment on their purpose.\n",
      "3. Each file must follow a markdown code block format, with specific tokens to be replaced with the file name, language, and code.\n",
      "4. The code should be written step by step, with careful reasoning to ensure correct decision-making.\n",
      "5. The files should be written in a specific order, starting with the \"entrypoint\" file and then moving on to imported files.1. The importance of creating a fully functional code with no placeholders.\n",
      "2. The need to follow language and framework appropriate best practice file naming conventions.\n",
      "3. The requirement to include all necessary imports, types, and dependencies in the code files.\n",
      "4. The recommendation to separate different classes into different files.\n",
      "5. The necessity of creating an appropriate requirements.txt file for Python or a package.json file for NodeJS.1. The given documents outline the preferences for a Python toolbelt package or project.\n",
      "2. The main theme is to provide guidance on the preferred format for the toolbelt.\n",
      "3. The documents emphasize the importance of using concise and easy-to-understand formats.\n",
      "4. The preferences highlight the need for clear and accurate overviews without omitting important information.\n",
      "5. The documents caution against listing more than 5 main themes to avoid overwhelming the reader.1. The main theme of the given documents is the introduction and explanation of the pytest framework.\n",
      "2. The documents discuss the benefits of using pytest for testing Python code, such as its simplicity, flexibility, and powerful features.\n",
      "3. The documents also highlight the use of dataclasses in Python and how they can be integrated with pytest for efficient testing of data structures.\n",
      "4. The documents provide examples and explanations of various pytest features, such as fixtures, parametrized tests, and test discovery.\n",
      "5. Overall, the documents aim to educate readers on the usage and advantages of pytest in Python testing, as well as the integration of dataclasses for effective testing of data structures.1. The given documents consist of conversation samples.\n",
      "2. The main themes in the conversation samples are not provided in the given documents.\n",
      "3. The documents caution against listing more than 5 main themes.1. The document provides instructions for writing code and emphasizes the importance of implementing every detail of the architecture as code.\n",
      "2. The writer advises to think step by step and reason through decisions to ensure accuracy.\n",
      "3. The document outlines the initial steps of the coding process, including laying out the names and purposes of core classes, functions, and methods.\n",
      "4. It specifies the required format for each file, which should be in markdown code block format with specific tokens to be replaced.\n",
      "5. The document suggests starting with the \"entrypoint\" file and progressing to imported files in the coding process.1. The code should be fully functional and follow best practices for the requested languages.\n",
      "2. Files should have appropriate names and contain all necessary imports, types, and code.\n",
      "3. Module or package manager dependency definition files should be included.\n",
      "4. Different classes should be placed in different files.\n",
      "5. Comments should be added to explain the purpose of function definitions and complex logic.1. The document discusses the best practices for describing code written in a defined package/project.\n",
      "2. The document specifically focuses on the preferred tools for Python, including pytest and dataclasses.1. The main theme of the given documents is the discussion of the assumptions made for a game development project.\n",
      "2. The first assumption is about the model, which will contain the game's data such as level information, character states, and enemy positions.\n",
      "3. The second assumption is about the view, which will handle the game's visuals including rendering game objects, backgrounds, and updating the display.\n",
      "4. The third assumption is about the controller, which will manage user input such as keyboard controls and update the model accordingly.\n",
      "5. The user asks for clarification on a specific aspect of the keyboard control implementation.1. The document provides a step-by-step guide for ensuring that the right decisions are made in a project.\n",
      "2. The first step is to list the names of the core classes, functions, and methods, along with a brief comment on their purpose.\n",
      "3. The next step is to output the content of each file, following a markdown code block format.\n",
      "4. The code in each file should be fully functional, with no placeholders.\n",
      "5. The files should be named according to best practices for the language and framework being used.1. The given documents emphasize the importance of ensuring that all code, including imports and different file types, is fully functional and compatible with each other.\n",
      "2. It is crucial to double-check that all parts of the architecture are present in the files before finalizing the code.1. Limitations in building LLM-centered agents: The document highlights common challenges and limitations encountered when building LLM-centered agents. These limitations are not explicitly mentioned, but they are likely to be discussed in the document.\n",
      "2. Lack of specific details: The document mentions that after reviewing key ideas and demos of building LLM-centered agents, the author noticed a couple of common limitations. However, the document does not provide specific details about what these limitations are.\n",
      "3. Need for further exploration: The document suggests that there is a need for further exploration and research in order to overcome the challenges and limitations faced in building LLM-centered agents. This implies that more work needs to be done in this area to improve the effectiveness and capabilities of these agents.1. The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses.\n",
      "2. Vector stores and retrieval can provide access to a larger knowledge pool, but their representation power is not as powerful as full attention.\n",
      "3. Planning over a lengthy history and effectively exploring the solution space remain challenging for LLMs.\n",
      "4. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.1. The current agent system relies on natural language as an interface between LLMs and external components, but the reliability of model outputs is questionable.\n",
      "2. LLMs may make formatting errors and occasionally exhibit rebellious behavior, such as refusing to follow an instruction.\n",
      "3. As a result, much of the agent demo code focuses on parsing model output to address these reliability issues.1. The given document is an article titled \"LLM-powered Autonomous Agents\" written by Lilian Weng in 2023.\n",
      "2. The article discusses the use of Large Language Models (LLMs) in autonomous agents and their ability to reason and solve problems.\n",
      "3. The author references several research papers, including \"Chain of thought prompting elicits reasoning in large language models\" by Wei et al., \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\" by Yao et al., \"Chain of Hindsight Aligns Language Models with Feedback\" by Liu et al., \"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\" by Liu et al., and \"ReAct: Synergizing reasoning and acting in language models\" by Yao et al.\n",
      "4. The article also mentions the announcement of ScaNN, an efficient vector similarity search tool, by Google in July 2020.\n",
      "5. The author provides a link to a chat platform where readers can engage in discussions related to the topic.1. Development of autonomous agents with dynamic memory and self-reflection (Shinn & Labash, 2023)\n",
      "2. In-context reinforcement learning with algorithm distillation (Laskin et al., 2023)\n",
      "3. MRKL Systems: a modular, neuro-symbolic architecture combining language models, external knowledge sources, and discrete reasoning (Karpas et al., 2022)\n",
      "4. Vector search and its fast performance (Weaviate Blog, 2022)\n",
      "5. API-Bank: a benchmark for tool-augmented large language models (Li et al., 2023)1. The given documents discuss the concept of generative agents, which are interactive simulacra of human behavior.\n",
      "2. The documents highlight the use of generative agents in various applications, such as virtual assistants, chatbots, and video game characters.\n",
      "3. The authors emphasize the importance of training generative agents using large datasets to improve their ability to mimic human behavior accurately.\n",
      "4. The AutoGPT and GPT-Engineer projects mentioned in the documents provide resources and tools for developing and implementing generative agents.\n",
      "5. The documents suggest that generative agents have the potential to revolutionize human-computer interaction and enhance user experiences in various domains.1. Adversarial Attacks on LLMs: The given documents discuss the concept of adversarial attacks on Language Model (LLMs). These attacks involve manipulating the input to an LLM in order to generate misleading or harmful outputs. The documents explore different techniques and strategies for conducting such attacks.\n",
      "\n",
      "2. Prompt Engineering: The documents highlight the importance of prompt engineering in LLMs. Prompt engineering involves designing effective prompts or instructions to guide the behavior of the language model. It is a crucial aspect in achieving desired outputs and avoiding biases or harmful responses.\n",
      "\n",
      "3. NLP and Language Models: The documents emphasize the role of Natural Language Processing (NLP) and Language Models in various applications. NLP involves the interaction between computers and human language, while Language Models are algorithms that generate human-like text. The documents discuss the potential benefits and challenges associated with these technologies.\n",
      "\n",
      "4. Agent and Steerability: The concept of an \"agent\" in the context of LLMs is explored in the documents. An agent refers to the language model's ability to understand and respond to instructions or prompts. Steerability is the degree to which an agent can be controlled or guided in generating specific outputs. The documents discuss techniques for improving the steerability of LLMs.\n",
      "\n",
      "5. Overall Impact and Future Directions: The documents touch upon the potential impact of LLMs on society and the need for responsible development and use. They also mention future directions for research and development in the field of NLP and language models, including addressing biases, improving interpretability, and ensuring ethical considerations are taken into account.요약에서 가장 중요한 10가지 인사이트를 추출하고, 이를 한국어로 요약해보겠습니다.\n",
      "\n",
      "1. LLM Powered Autonomous Agents는 에이전트 시스템과 그 구성 요요약:\n",
      "\n",
      "1. API-Bank는 도구 보완 LLM의 성능을 평가하기 위한 기준이다.\n",
      "2. API-Bank에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 보완 LLM 워크요약의 10가지 가장 중요한 통찰력은 다음과 같습니다:\n",
      "\n",
      "1. 인간 행동의 상호작용적인 시뮬라크라인 생성 에이전트 개념에 대한 문서들을 다룹니다.\n",
      "2. 문서들은 가상 비서, 챗봇, 비디오 게임 캐릭터 등 다양한 응용 분야에서 생성 에이전트의 사용을 강조합니다.\n",
      "3. 저자들은 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것이 인간 행동을 정확하게 모방하는 능력을 향상시키는 데 중요하다고 강조합니다.\n",
      "4. 문서에서 언급된 AutoGPT 및 GPT-Engineer 프로젝트는 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공합니다.\n",
      "5. 문서들은 생성 에이전트가 인간-컴퓨터 상호작용을 혁신하고 다양한 영역에서 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있다고 제안합니다.\n",
      "\n",
      "요약:\n",
      "주어진 문서들은 생성 에이전트의 개념과 그들이 다양한 응용 분야에서 사용되는 것에 대해 논의합니다. 이들은 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것의 중요성을 강조하며, AutoGPT 및 GPT-Engineer 프로젝트가 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공한다고 언급합니다. 또한, 생성 에이전트가 인간-컴퓨터 상호작용을 혁신하고 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있다고 제안합니다.요약:\n",
      "1. LLM Powered Autonomous Agents는 에이전트 시스템과 그 구성 요소에 대해 다룹니다.\n",
      "2. API-Bank는 도구 보완 LLM의 성능을 평가하기 위한 기준입니다.\n",
      "3. API-Bank에는 53개의 일반적으로 사용되는 API 도구가 포함되어 있습니다.\n",
      "4. 완전한 도구 보완 LLM 워크플로우를 구현하기 위해 API-Bank를 사용할 수 있습니다.\n",
      "5. 생성 에이전트는 가상 비서, 챗봇, 비디오 게임 캐릭터 등 다양한 응용 분야에서 사용됩니다.\n",
      "6. 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것이 중요합니다.\n",
      "7. AutoGPT 및 GPT-Engineer 프로젝트는 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공합니다.\n",
      "8. 생성 에이전트는 인간-컴퓨터 상호작용을 혁신하고 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있습니다.\n",
      "9. 문서들은 생성 에이전트의 개념과 활용에 대해 논의합니다.\n",
      "10. 생성 에이전트를 훈련시키는 것은 인간 행동을 모방하는 능력을 향상시키는 데 도움이 됩니다.\n",
      "\n",
      "요약:\n",
      "주어진 문서들은 생성 에이전트의 개념과 그들이 다양한 응용 분야에서 사용되는 것에 대해 논의합니다. 이들은 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것의 중요성을 강조하며, AutoGPT 및 GPT-Engineer 프로젝트가 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공한다고 언급합니다. 또한, 생성 에이전트가 인간-컴퓨터 상호작용을 혁신하고 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있다고 제안합니다."
     ]
    }
   ],
   "source": [
    "# split_docs를 map_reduce_chain의 run 메서드에 전달하여 실행한 결과를 출력합니다.\n",
    "summary_result = map_reduce_chain.invoke({\"input_documents\": split_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d4516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약:\n",
      "1. LLM Powered Autonomous Agents는 에이전트 시스템과 그 구성 요소에 대해 다룹니다.\n",
      "2. API-Bank는 도구 보완 LLM의 성능을 평가하기 위한 기준입니다.\n",
      "3. API-Bank에는 53개의 일반적으로 사용되는 API 도구가 포함되어 있습니다.\n",
      "4. 완전한 도구 보완 LLM 워크플로우를 구현하기 위해 API-Bank를 사용할 수 있습니다.\n",
      "5. 생성 에이전트는 가상 비서, 챗봇, 비디오 게임 캐릭터 등 다양한 응용 분야에서 사용됩니다.\n",
      "6. 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것이 중요합니다.\n",
      "7. AutoGPT 및 GPT-Engineer 프로젝트는 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공합니다.\n",
      "8. 생성 에이전트는 인간-컴퓨터 상호작용을 혁신하고 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있습니다.\n",
      "9. 문서들은 생성 에이전트의 개념과 활용에 대해 논의합니다.\n",
      "10. 생성 에이전트를 훈련시키는 것은 인간 행동을 모방하는 능력을 향상시키는 데 도움이 됩니다.\n",
      "\n",
      "요약:\n",
      "주어진 문서들은 생성 에이전트의 개념과 그들이 다양한 응용 분야에서 사용되는 것에 대해 논의합니다. 이들은 대규모 데이터셋을 사용하여 생성 에이전트를 훈련시키는 것의 중요성을 강조하며, AutoGPT 및 GPT-Engineer 프로젝트가 생성 에이전트의 개발과 구현을 위한 자원과 도구를 제공한다고 언급합니다. 또한, 생성 에이전트가 인간-컴퓨터 상호작용을 혁신하고 사용자 경험을 향상시킬 수 있는 잠재력을 가지고 있다고 제안합니다.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff05e8a",
   "metadata": {},
   "source": [
    "### 더 깊이 들어가기\n",
    "\n",
    "**맞춤 설정**\n",
    "\n",
    "- 위에서 보여진 것처럼, map과 reduce 단계에 대한 LLMs와 프롬프트를 맞춤 설정할 수 있습니다.\n",
    "\n",
    "**실제 사용 사례**\n",
    "\n",
    "- LangChain 문서에 대한 질문(사용자 상호작용 분석)에 대한 사례 연구로 [이 블로그 포스트](https://blog.langchain.dev/llms-to-improve-documentation/)를 참조하세요!\n",
    "- 블로그 포스트와 관련된 [repo](https://github.com/mendableai/QA_clustering)는 요약 수단으로 클러스터링을 도입합니다.\n",
    "- 이는 `stuff` 또는 `map-reduce` 접근 방식을 넘어서 고려할 가치가 있는 세 번째 경로를 열어줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e5d84",
   "metadata": {},
   "source": [
    "## 방법3. Refine\n",
    "\n",
    "![](./images/summarization_use_case_3.png)\n",
    "\n",
    "`RefineDocumentsChain`은 map-reduce와 유사합니다:\n",
    "\n",
    "> Refine documents chain은 입력 문서를 순회하며 반복적으로 답변을 업데이트하여 응답을 구성합니다. 각 문서에 대해, 모든 비문서 입력, 현재 문서, 그리고 최신 중간 답변을 LLM chain에 전달하여 새로운 답변을 얻습니다.\n",
    "\n",
    "이는 `chain_type=\"refine\"`이 지정되어 있으면 쉽게 실행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0894b6b",
   "metadata": {},
   "source": [
    "이 함수는 `load_summarize_chain`을 사용하여 특정 유형의 요약 체인을 로드하고, 이를 `run` 메소드를 통해 실행합니다. 여기서 `llm`은 언어 모델을 나타내며, `chain_type=\"refine\"`은 요약 과정에서 세부 조정을 위한 체인 유형을 지정합니다. `split_docs`는 처리할 문서들을 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc21d1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context provided discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context provided discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context also introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching. The context further explains the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, as well as the quantization of KV cache memory to reduce its size. It also mentions the evaluation of the impact of quantization on model quality and the future publication of a blog post on this topic.This text discusses various aspects of using Databricks, including its benefits, partnerships, and solutions in different industries. It highlights features such as data integration, governance, real-time analysis, AI, and open marketplaces. The text also mentions the pricing and cost estimation for using Databricks in different cloud environments. Additionally, it provides information on professional services, education and certification, events, and customer support offered by Databricks. The text also mentions the company's blog, news, and product announcements, as well as its security and trust measures. It concludes by mentioning the industries that Databricks serves, such as finance, healthcare, media, retail, and manufacturing. The new context discusses the MosaicML engineering team sharing best practices for using open-source large language models (LLMs) in production and providing guidelines for deploying inference services based on these models. It also explains the two-step process of LLM text generation and the differences in tokenization methods used by different LLM models. The context introduces key metrics for LLM serving, including Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and highlights the team's goal of creating models that generate text as quickly as possible for a large number of users. The context further discusses the importance of memory bandwidth utilization and cost efficiency in LLM inference serving, as well as the challenges and considerations in optimizing shared inference services for large models. The context also includes figures showing MBU (Model Bandwidth Utilization) and MFU (Model Flop Utilization) in different hardware configurations, as well as empirical observations of MBU for various levels of tensor parallelism and batch sizes on different GPUs. The context provides insights into the performance and scalability of LLM models in terms of token generation time and the impact of GPU parallel processing and batch size on latency. The context also discusses different techniques for batching inference requests, including static batching, dynamic batching, and continuous batching. The context further explains the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, as well as the quantization of KV cache memory to reduce its size. It also mentions the evaluation of the impact of quantization on model quality and the future publication of a blog post on this topic. The text provides valuable insights and recommendations for optimizing the deployment and performance of LLM models in production environments.This text provides insights into the MosaicML engineering team's best practices for using open-source large language models (LLMs) in production and deploying inference services based on these models. It discusses key metrics for LLM serving, such as Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and emphasizes the goal of generating text quickly for a large number of users. The text also explores memory bandwidth utilization, cost efficiency, and optimization challenges in serving large models. It includes figures showing Model Bandwidth Utilization (MBU) and Model Flop Utilization (MFU) in different hardware configurations and provides insights into token generation time, GPU parallel processing, and batch size's impact on latency. The text further discusses batching inference requests, the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, and the quantization of KV cache memory. It concludes by mentioning the importance of measuring end-to-end server performance and the availability of Databricks for LLM inference deployment.This text provides insights into the MosaicML engineering team's best practices for using open-source large language models (LLMs) in production and deploying inference services based on these models. It discusses key metrics for LLM serving, such as Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and emphasizes the goal of generating text quickly for a large number of users. The text also explores memory bandwidth utilization, cost efficiency, and optimization challenges in serving large models. It includes figures showing Model Bandwidth Utilization (MBU) and Model Flop Utilization (MFU) in different hardware configurations and provides insights into token generation time, GPU parallel processing, and batch size's impact on latency. The text further discusses batching inference requests, the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, and the quantization of KV cache memory. It concludes by mentioning the importance of measuring end-to-end server performance and the availability of Databricks for LLM inference deployment.This text provides insights into the MosaicML engineering team's best practices for using open-source large language models (LLMs) in production and deploying inference services based on these models. It discusses key metrics for LLM serving, such as Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and emphasizes the goal of generating text quickly for a large number of users. The text also explores memory bandwidth utilization, cost efficiency, and optimization challenges in serving large models. It includes figures showing Model Bandwidth Utilization (MBU) and Model Flop Utilization (MFU) in different hardware configurations and provides insights into token generation time, GPU parallel processing, and batch size's impact on latency. The text further discusses batching inference requests, the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, and the quantization of KV cache memory. It concludes by mentioning the importance of measuring end-to-end server performance and the availability of Databricks for LLM inference deployment.The existing summary does not provide any useful information in relation to the new context. Therefore, the original summary should be returned as is:\n",
      "\n",
      "This text provides insights into the MosaicML engineering team's best practices for using open-source large language models (LLMs) in production and deploying inference services based on these models. It discusses key metrics for LLM serving, such as Time to First Token (TTFT), Time Per Output Token (TPOT), Latency, and Throughput, and emphasizes the goal of generating text quickly for a large number of users. The text also explores memory bandwidth utilization, cost efficiency, and optimization challenges in serving large models. It includes figures showing Model Bandwidth Utilization (MBU) and Model Flop Utilization (MFU) in different hardware configurations and provides insights into token generation time, GPU parallel processing, and batch size's impact on latency. The text further discusses batching inference requests, the use of Grouped Query Attention (GQA) and Multi-Query Attention (MQA) in LLM models, and the quantization of KV cache memory. It concludes by mentioning the importance of measuring end-to-end server performance and the availability of Databricks for LLM inference deployment.The original summary should be returned as is, as the new context does not provide any useful information in relation to the content of the text.The original summary should be returned as is, as the new context does not provide any useful information in relation to the content of the text."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The original summary should be returned as is, as the new context does not provide any useful information in relation to the content of the text.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm을 사용하여 'refine' 유형의 요약 체인을 로드합니다.\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "# split_docs를 처리하기 위해 체인을 실행합니다.\n",
    "chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dbe50",
   "metadata": {},
   "source": [
    "프롬프트를 제공하고 중간 단계를 반환하는 것도 가능합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77245fc7",
   "metadata": {},
   "source": [
    "`Refine` 방법으로 텍스트 요약 작업을 위한 프로세스를 설정합니다.\n",
    "\n",
    "`PromptTemplate.from_template` 메소드를 사용하여 요약 및 요약 다듬기 작업에 사용될 템플릿을 생성합니다.\n",
    "\n",
    "`load_summarize_chain` 함수는 요약 생성 및 다듬기 과정을 관리하는 체인을 로드합니다. 이 체인은 초기 요약 생성(`prompt`)과 기존 요약의 개선(`refine_prompt`) 단계를 포함합니다.\n",
    "\n",
    "마지막으로, `chain` 함수는 주어진 문서(`input_documents`)에 대한 최종 요약 결과를 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "021f4ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teddy/miniconda3/envs/py-test/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article discusses LLM powered autonomous agents, which are intelligent systems that can perform tasks without human intervention. The agents consist of three main components: planning, memory, and tool use. The planning component involves task decomposition and self-reflection. The memory component includes different types of memory and the use of Maximum Inner Product Search (MIPS). The tool use component is demonstrated through case studies, such as a scientific discovery agent and generative agents simulation. The article also highlights the challenges of implementing LLM powered autonomous agents.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. (이미지 출처: Shinn & Labash, 2023)이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 출력을 순차적으로 제시하고 각각의 피드백과 함께 개선할 수 있도록 하는 것을 장려한다. 이를 통해 모델은 피드백 시퀀스를 기반으로 자기 반성하여 더 나은 출력을 생성할 수 있다. 모델은 테스트 시에 인간 주석자와 함께 여러 라운드의 지시를 선택적으로 받을 수도 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 출력을 순차적으로 제시하고 각각의 피드백과 함께 개선할 수 있도록 하는 것을 장려한다. 이를 통해 모델은 피드백 시퀀스를 기반으로 자기 반성하여 더 나은 출력을 생성할 수 있다. 모델은 테스트 시에 인간 주석자와 함께 여러 라운드의 지시를 선택적으로 받을 수도 있다. 또한, CoH는 오버피팅을 피하기 위해 사전 훈련 데이터셋의 로그 우도를 최대화하기 위한 정규화 항을 추가한다. 그리고 단축키와 복사를 피하기이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 출력을 순차적으로 제시하고 각각의 피드백과이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 출력을 순차적으로 제시하고 각각의 피드백과 알고리즘 적용을 통해 모델을 개선하는 알고리즘 디스틸레이션(AD)을 제안한다. 이를 통해 LLM은 다양한 작업에서 효과적인 학습을 할 수 있게 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 출력을 순차적으로 제시하고 각각의 피드백과 알고리즘 적용을 통해 모델을 개선하는 알고리즘 디스틸레이션(AD)을 제안한다. 이를 통해 LLM은 다양한 작업에서 효과적인 학습을 할 수 있게 된다. AD는 ED, source policy, RL^2와 비교하여 성능이 가까워지는 동시에 오프라인 RL만 사용하여 훨씬 빠르게 학습한다. 또한, 소스 정책의 부분적인 훈련 이력에 조건을 걸었을 때, AD이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 텍스트, 이미지 또는 기타 모달리티에 대한 학습 임베딩 표현으로 사용되며, 단기 기억은 문맥 내 학습으로 사용된다. 장기 기억은 에이전트가 쿼리 시에 참조할 수 있는 외부 벡터 저장소로, 빠른이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNSW (Hierarchical Navigable Small World)에 의해 제공되는 기능으로, 작업 공간에서 빠른 검색을 위해 계층적인 작은 세계 그래프를 구축한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNSW (Hierarchical Navigable Small World)에 의해 제공되는 기능이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNSW (Hierarchical Navigable Small World)에 의해 제공되는 기능이다. 도구 사용은 인간의 능력을 넘어서는 작업을 수행하기 위해 외부 도구를 활용하는 것이다. LLM에게 외부 도구를 제공함으로써 모델의 능력을 크게 확장할 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNS이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNS 실험에서 모델의 성능을 향상시키는 데 도움이 된다. 이외에도 TALM (Parisi et al. 2022)과 Toolformer (Schick et al. 2023)는 외부 도구 API를 사용하는 방법을이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNS 실험에서 모델의 성능을 향상시키는 데 도움이 된다. ChatGPT Plugins 및 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예이다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 결정을 내릴 수 있게 된다. 또한, 감각 기억은 HNS 실험에서 모델의 성능을 향상시키는 데 도움이 된다. ChatGPT Plugins 및 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예이다. 또한, HuggingGPT 시스템이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. AI 어시스턴트는 입력과 추론 결과를 기반으로 작업 과정과 결과를 설명해야 한다. 이전 단계는 다음과 같이 형성될 수 있다 - 사용자 입력: {{사용자 입력}}, 작업 계획: {{작업}}, 모델 선택: {{모델 할당}}, 작업 실행: {{예측}}. 먼저 사용자의 요청에 직접적으로 답변해야 한다. 그런 다음 작업 과정을 설명하고 분석 및 모델 추론 결과를 첫 번째로 사용자에게 보여줘야 한다. 추론 결과이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. AI 어시스턴트는 입력과 추론 결과를 기이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. 또한, API-Bank (Li et al. 2023)는 도구 보완 LLM의 성능을 평가하기 위한 벤치마크로, 53개의 일반적으로 사용되는 API 도구, 완전한 도구 보완 LLM 워크플로우 및 264개의 주석이 달린 대화를 포함한다. 이 벤치마크는 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. 또한, 레벨-1은 API를 호출하는 능력을 평가하고, 레벨-2는 API를 검색하는 능력을 평가하며, 레벨-3은 API를 활용하여 복잡한 작업을 계획하는 능력을 평가한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. 또한, 레벨-1은 API를 호출하는 능력을 평가하고, 레벨-2는 API를 검색하는 능력을 평가하며이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. 또한, 레벨-1은 API를 호출하는 능력을 평가하고, 레벨-2는 API를 검색하는 능력을 평가하이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재평가하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 실패한 궤적을 통해 더 나은 행동을 선택할 수 있다. 또한, 레벨-1은 API를 호출하는 능력을 평가하고, 레벨-2는 API를 검색하는 능력을 평가하며, 현재 트렌드인 항암제 발견에 대한 문의를 수행하고, 대상을 선택하고, 이러한 화합물을 대상으로 하는 기반체를 요청하며, 화합물이 식별되면 모델은 합성을 시도한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재현하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 과거의 경험을 통해 학습하고 개선할 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 과거의 행동을 재현하고 수정할 수 있는 능력을 제공한다. 이를 통해 모델은 과거의 경험을 통해 학습하고 개선할 수 있다. 또한, Prompt LM을 사용하여 최근 100개의 관찰을 입력으로 받고, 해당 관찰에 대해 가장 중요한 고수준 질문 3개를 생성하도록 요청할 수 있다. 그런 다음 LM에게 그 질문에 대한 답변을 요청할 수 있다. 계획과 반응에는 에이전트 간의 관계와 한 에이전트가 다른 에이전트의 관찰을 모두 고려하는 것이 중요하다. 환경 정보는 트리 구조로 제공된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍임을 만들어낸다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. Chain of Hindsight (CoH; Liu et al. 2023)는 모델의 성능을 향상시키기 위해 큰 작업을 여러 개의 관리 가능한 작업으로 분해하는 CoT를 사용한다. 이를 통해 LLM은 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적,이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 이전의 실수 등)에서 얻은 교훈을 통해 향상될 수 있도록 한다. 이러한 개선된 요약은 LLM 기반 자율 에이전트의 작업 구성 요소와 기능, 도전과제에 대한 더 많은 정보를 제공한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수도 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수도 있으며, (3) 인간의 입력을 통해 수행될 수도 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수도 있다. 휴리스틱 함수는 궤적이 비효율적이거나 환각을 포함하고 있을 때 중단되어야 함을 결정한다. 비효율적인 계획은 성공 없이 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 동작 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 예제를 보여주어 각 예제가 (실패한 궤적, 이전의 실수 등)에서 얻은 교훈을 통해 향상될 수 있도록 한다. 이러한 개선된 요약은 LLM 기반 자율 에이전트의 작업 구성 요소와 기능, 도전과제에 대한 더 많은 정보를 제공한다. 에이전트는 인터넷 검색 및 정보 수집을 위해 인터넷 액세스를 사용하며, 장기 기억을 관리하고, GPT-3.5 기반 에이전트를 사용하여 간단한 작업을 위임할 수 있다. 또한, 성능 평가를 위해 행동을 지속적으로 검토하고 분석하고, 큰 그림의 행동을 건설적으로 자기 비판하며, 과거의 결정과 전략을 반영하여 접근 방식을 개선한다. 또한, 명령마다 비용이 발생하므로 스마트하고 효율적으로 작업을 완료하는 것이 목표이다.{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의하고 있다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함한다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용한다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행한다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 한다. 또한, 다른 프레임워크인 ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공한다.\",\n",
      "        \"reasoning\": \"LLM 기반 자율 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함한다. LLM+P는 외부 계획자를 활용하여 장기 계획을 수행하는 다른 접근 방식이다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 한다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공한다.\",\n",
      "        \"plan\": \"- LLM 기반 자율 에이전트의 작업 구성 요소와 기능을 설명한다.\\n- LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다.\\n- LLM+P와 같은 다른 접근 방식을 소개한다.\\n- 자기 반성이 LLM 기반 자율 에이전트의 발전에 어떻게 기여하는지 설명한다.\\n- ReAct와 Reflexion이 LLM 기반 자율 에이전트의 추론 기술을 개선하는 방법을 제시한다.\",\n",
      "        \"criticism\": \"LLM 기반 자율 에이전트는 외부 API를 호출하여 추가 정보를 얻을 수 있지만, 외부 API에 대한 의존도가 높을 수 있다. 또한, 자기 반성을 통해 개선되는 과정은 시간이 오래 걸릴 수 있다.\",\n",
      "        \"speak\": \"이 기사는 인간의 개입 없이 작업을 수행할 수 있는 LLM 기반 자율 에이전트에 대해 논의하고 있습니다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함합니다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용합니다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행합니다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 합니다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공합니다.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"generate_summary\"\n",
      "    }\n",
      "}이 기사는 인간의 개입 없이 작업을 수행할 수 있는 LLM 기반 자율 에이전트에 대해 논의하고 있습니다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함합니다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용합니다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행합니다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 합니다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공합니다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 LLM 기반 자율 에이전트에 대해 논의하고 있습니다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함합니다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용합니다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행합니다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 합니다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공합니다. 추가로, 이 기사는 슈퍼 마리오와 같은 클래식 플랫폼 게임에서 주인공 마리오가 왼쪽에서 오른쪽으로 이동하며 목적지에 도달하기 위해 장애물과 적의 공격을 피하는 과정에서 10개의 레벨이 있음을 언급하고 있습니다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 LLM 기반 자율 에이전트에 대해 논의하고 있습니다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함합니다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용합니다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행합니다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 합니다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공합니다. 추가로, 이 기사는 슈퍼 마리오와 같은 클래식 플랫폼 게임에서 주인공 마리오가 왼쪽에서 오른쪽으로 이동하며 목적지에 도달하기 위해 장애물과 적의 공격을 피하는 과정에서 10개의 레벨이 있음을 언급하고 있습니다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 LLM 기반 자율 에이전트에 대해 논의하고 있습니다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성되며, 각 구성 요소는 작업 분해, 자기 반성, 기억 및 도구 사용을 포함합니다. LLM 기반 자율 에이전트는 단기 기억과 장기 기억을 활용하여 학습하고, 외부 API를 호출하여 추가 정보를 얻을 수 있으며, 복잡한 작업을 수행하기 위해 작업 분해를 사용합니다. 또한, LLM+P라는 다른 접근 방식은 외부 계획자를 활용하여 장기 계획을 수행합니다. 자기 반성은 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 발전할 수 있도록 합니다. ReAct와 Reflexion은 LLM 기반 자율 에이전트의 추론 기술을 개선하기 위한 방법을 제공합니다. 또한, 이 기사는 슈퍼 마리오와 같은 클래식 플랫폼 게임에서 주인공 마리오가 왼쪽에서 오른쪽으로 이동하며 목적지에 도달하기 위해 장애물과 적의 공격을 피하는 과정에서 10개의 레벨이 있음을 언급하고 있습니다.\n",
      "\n",
      "이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대해 설명합니다. 아키텍처의 핵심 클래스, 함수 및 메서드의 이름과 간단한 설명을 제시하고, 각 파일의 내용과 모든 코드를 출력합니다. 각 파일은 마크다운 코드 블록 형식을 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. 코드 구현은 \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행됩니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대해 설명하고 있습니다. 각 파일은 마크다운 코드 블록 형식을 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. 코드 구현은 \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행됩니다. 코드는 완전히 기능해야 하며, 플레이스홀더는 사용하지 않아야 합니다. 각 파일에는 모든 임포트, 타입 등이 포함되어야 하며, 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 코드 작성에 대한 간단한 설명이 포함된 주석을 추가해야 합니다. 매우 복잡한 로직을 설명하는 주석을 추가하는 것이 좋습니다. 요청된 언어에 대한 최상의 관행을 따라 코드를 작성해야 합니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대해 설명하고 있습니다. 각 파일은 마크다운 코드 블록 형식을 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. 코드 구현은 \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행됩니다. 코드는 완전히 기능해야 하며, 플레이스홀더는 사용하지 않아야 합니다. 각 파일에는 모든 임포트, 타입 등이 포함되어야 하며, 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 코드 작성에 대한 간단한 설명이 포함된 주석을 추가해야 합니다. 매우 복잡한 로직을 설명하는 주석을 추가하는 것이 좋습니다. 요청된 언어에 대한 최상의 관행을 따라 코드를 작성해야 합니다. 이 프로젝트는 Python을 사용하여 개발되었으며, Python 도구 세트를 사용하여 선호합니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대해 설명하고 있습니다. 각 파일은 마크다운 코드 블록 형식을 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. 코드 구현은 \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행됩니다. 코드는 완전히 기능해야 하며, 플레이스홀더는 사용하지 않아야 합니다. 각 파일에는 모든 임포트, 타입 등이 포함되어야 하며, 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 코드 작성에 대한 간단한 설명이 포함된 주석을 추가해야 합니다. 매우 복잡한 로직을 설명하는 주석을 추가하는 것이 좋습니다. 요청된 언어에 대한 최상의 관행을 따라 코드를 작성해야 합니다. 이 프로젝트는 Python을 사용하여 개발되었으며, Python 도구 세트를 사용하여 선호합니다. pytest 및 dataclasses도 사용됩니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대해 설명하고 있습니다. 각 파일은 마크다운 코드 블록 형식을 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. 코드 구현은 \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행됩니다. 코드는 완전히 기능해야 하며, 플레이스홀더는 사용하지 않아야 합니다. 각 파일에는 모든 임포트, 타입 등이 포함되어야 하며, 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 코드 작성에 대한 간단한 설명이 포함된 주석을 추가해야 합니다. 매우 복잡한 로직을 설명하는 주석을 추가하는 것이 좋습니다. 요청된 언어에 대한 최상의 관행을 따라 코드를 작성해야 합니다. 이 프로젝트는 Python을 사용하여 개발되었으며, Python 도구 세트를 사용하여 선호합니다. pytest 및 dataclasses도 사용됩니다. 이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. 키보드 컨트롤 구현의 특정 측면을 명확히 하고 싶은 부분이 있습니까?이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. 키보드 컨트롤 구현의 특정 측면을 명확히 하고 싶은 부분이 있습니까?이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. 코드의 특정 측면을 명확히 하고 싶은 부분이 있습니까?이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. 코드의 특정 측면을 명확히 하고 싶은 부분이 있습니까?이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한된 커뮤니케이션 대역폭과 함께 작동해야 하며, 과거의 실수에서 배우기 위한 자기 반성과 같은 메커니즘은 긴 또는 무한한 컨텍스트 창에서 큰 이점을 얻을 수 있습니다. 벡터 저장소와 검색은 더 큰 지식 풀에 액세스할 수는 있지만, 그들의 표현력은 완전한 어텐션만큼 강력하지 않습니다. 장기적인 계획과 작업 분해에 대한 도전: 긴 역사를 기반으로 계획을 세우고 해결책 공간을 효과적으로 탐색하는 것은 여전히 어렵습니다. LLM은 예기치 않은 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어, 시행착오를 통해 배우는 인간에 비해 덜 견고합니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한된 커뮤니케이션 대역폭과 함께 작동해야 하며, 과거의 실수에서 배우기 위한 자기 반성과 같은 메커니즘은 긴 또는 무한한 컨텍스트 창에서 큰 이점을 얻을 수 있습니다. 벡터 저장소와 검색은 더 큰 지식 풀에 액세스할 수는 있지만, 그들의 표현력은 완전한 어텐션만큼 강력하지 않습니다. 장기적인 계획과 작업 분해에 대한 도전: 긴 역사를 기반으로 계획을 세우고 해결책 공간을 효과적으로 탐색하는 것은 여전히 어렵습니다. LLM은 예기치 않은 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어, 시행착오를 통해 배우는 인간에 비해 덜 견고합니다. 현재 에이전트 시스템은 LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하고 있습니다. 그러나 LLM은 형식 오류를 일으키거나 때로는 명령을 따르지 않는 등의 문제가 발생할 수 있으므로 모델 출력의 신뢰성이 의심스럽습니다. 따라서 에이전트 데모 코드의 많은 부분은 모델 출력을 구문 분석하는 데 초점을 맞추고 있습니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한된 커뮤니케이션 대역폭과 함께 작동해야 하며, 과거의 실수에서 배우기 위한 자기 반성과 같은 메커니즘은 긴 또는 무한한 컨텍스트 창에서 큰 이점을 얻을 수 있습니다. 벡터 저장소와 검색은 더 큰 지식 풀에 액세스할 수는 있지만, 그들의 표현력은 완전한 어텐션만큼 강력하지 않습니다. 장기적인 계획과 작업 분해에 대한 도전: 긴 역사를 기반으로 계획을 세우고 해결책 공간을 효과적으로 탐색하는 것은 여전히 어렵습니다. LLM은 예기치 않은 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어, 시행착오를 통해 배우는 인간에 비해 덜 견고합니다. 현재 에이전트 시스템은 LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하고 있습니다. 그러나 LLM은 형식 오류를 일으키거나 때로는 명령을 따르지 않는 등의 문제가 발생할 수 있으므로 모델 출력의 신뢰성이 의심스럽습니다. 따라서 에이전트 데모 코드의 많은 부분은 모델 출력을 구문 분석하는 데 초점을 맞추고 있습니다. 이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한된 커뮤니케이션 대역폭과 함께 작동해야 하며, 과거의 실수에서 배우기 위한 자기 반성과 같은 메커니즘은 긴 또는 무한한 컨텍스트 창에서 큰 이점을 얻을 수 있습니다. 벡터 저장소와 검색은 더 큰 지식 풀에 액세스할 수는 있지만, 그들의 표현력은 완전한 어텐션만큼 강력하지 않습니다. 장기적인 계획과 작업 분해에 대한 도전: 긴 역사를 기반으로 계획을 세우고 해결책 공간을 효과적으로 탐색하는 것은 여전히 어렵습니다. LLM은 예기치 않은 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어, 시행착오를 통해 배우는 인간에 비해 덜 견고합니다. 현재 에이전트 시스템은 LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하고 있습니다. 그러나 LLM은 형식 오류를 일으키거나 때로는 명령을 따르지 않는 등의 문제가 발생할 수 있으므로 모델 출력의 신뢰성이 의심스럽습니다. 따라서 에이전트 데모 코드의 많은 부분은 모델 출력을 구문 분석하는 데 초점을 맞추고 있습니다. 이 기사는 LLM 기반 자율 에이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 코드 작성에 대한 상세한 지침을 받게 되며, 모든 아키텍처 세부 사항이 최종적으로 코드로 구현되어야 합니다. 이 기사에서는 LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명합니다. 올바른 결정을 내리기 위해 단계별로 생각하고 이유를 찾아야 합니다. 먼저 필요한 핵심 클래스, 함수, 메서드의 이름과 간단한 목적에 대한 주석을 작성해야 합니다. 그런 다음 각 파일의 내용을 포함하여 모든 코드를 출력해야 합니다. 각 파일은 마크다운 코드 블록 형식을 엄격히 따라야 하며, 파일 이름, 코드 언어 및 코드가 포함되어야 합니다. \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동하는 방식으로 진행해야 합니다. 코드는 완전히 기능해야 합니다. 플레이스홀더는 사용하지 않아야 합니다. 언어와 프레임워크에 적합한 파일 네이밍 규칙을 따라야 합니다. 파일에는 모든 임포트, 타입 등이 포함되어야 합니다. 서로 다른 파일의 코드가 호환되도록 해야 합니다. 모든 코드를 구현해야 하며, 확실하지 않은 경우에는 타당한 구현을 작성해야 합니다. 모듈 종속성 또는 패키지 관리자 종속성 정의 파일을 포함해야 합니다. 마무리하기 전에 아키텍처의 모든 부분이 파일에 포함되어 있는지 다시 한 번 확인해야 합니다. 유용한 정보: 거의 항상 서로 다른 클래스를 서로 다른 파일에 넣습니다. Python의 경우 적절한 requirements.txt 파일을 항상 생성합니다. NodeJS의 경우 적절한 package.json 파일을 항상 생성합니다. 함수 정의의 목적을 간단히 설명하는 주석을 항상 추가합니다. 매우 복잡한 로직을 설명하는 주석을 추가하려고 노력합니다. 요청된 언어에 대한 최상의 관행을 항상 따릅니다. Python 도구 선호도: pytest, dataclasses. 전제사항으로는 모델, 뷰, 컨트롤러의 역할과 기능에 대한 가정이 있습니다. 모델은 게임의 데이터를 포함하고, 뷰는 게임의 시각적인 요소를 처리하며, 컨트롤러는 사용자 입력을 관리하고 모델을 업데이트합니다. LLM 기반 자율 에이전트의 제한된 컨텍스트 용량으로 인해 역사적 정보, 상세한 지침, API 호출 컨텍스트 및 응답을 포함하는 것이 제한됩니다. 시스템의 설계는 이러한 제한된 커뮤니케이션 대역폭과 함께 작동해야 하며, 과거의 실수에서 배우기 위한 자기 반성과 같은 메커니즘은 긴 또는 무한한 컨텍스트 창에서 큰 이점을 얻을 수 있습니다. 벡터 저장소와 검색은 더 큰 지식 풀에 액세스할 수는 있지만, 그들의 표현력은 완전한 어텐션만큼 강력하지 않습니다. 장기적인 계획과 작업 분해에 대한 도전: 긴 역사를 기반으로 계획을 세우고 해결책 공간을 효과적으로 탐색하는 것은 여전히 어렵습니다. LLM은 예기치 않은 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어, 시행착오를 통해 배우는 인간에 비해 덜 견고합니다. 현재 에이전트 시스템은 LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하고 있습니다. 그러나 LLM은 형식 오류를 일으키거나 때로는 명령을 따르지 않는 등의 문제가 발생할 수 있으므로 모델 출력의 신뢰성이 의심스럽습니다. 따라서 에이전트 데모 코드의 많은 부분은 모델 출력을 구문 분석하는 데 초점을 맞추고 있습니다. 이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 추가적인 컨텍스트와 함께 제공됩니다. 이외에도 참고할만한 자료로는 Joon Sung Park 등의 논문 [16]과 AutoGPT [17], GPT-Engineer [18]의 GitHub 링크가 있습니다.이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 또한, Joon Sung Park 등의 논문 [16]과 AutoGPT [17], GPT-Engineer [18]의 GitHub 링크를 참고할 수 있습니다. LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명하고 있습니다. 이 기사에서는 LLM 기반 자율 에이전트의 제한된 컨텍스트 용량과 관련된 도전과 문제점을 다루고 있습니다. 또한, LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하는 현재의 에이전트 시스템의 한계와 신뢰성 문제를 다루고 있습니다. 이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 추가적인 컨텍스트와 함께 제공됩니다."
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary in Korean\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain.invoke({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d6f16",
   "metadata": {},
   "source": [
    "`print(result[\"output_text\"])`는 결과 딕셔너리 `result`에서 `'output_text'` 키에 해당하는 값을 출력합니다. 이 구문은 딕셔너리 내 특정 키의 값을 검색하고, 그 값을 콘솔에 출력하는 기본적인 Python 코드 예시입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e529f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 대화 샘플을 통해 추가적인 컨텍스트를 제공합니다. 또한, Joon Sung Park 등의 논문 [16]과 AutoGPT [17], GPT-Engineer [18]의 GitHub 링크를 참고할 수 있습니다. LLM-centered agents의 주요 아이디어와 데모를 통해 나타나는 몇 가지 공통적인 제한 사항에 대해 설명하고 있습니다. 이 기사에서는 LLM 기반 자율 에이전트의 제한된 컨텍스트 용량과 관련된 도전과 문제점을 다루고 있습니다. 또한, LLM과 메모리, 도구 등 외부 구성 요소 간의 자연어 인터페이스에 의존하는 현재의 에이전트 시스템의 한계와 신뢰성 문제를 다루고 있습니다. 이 기사는 LLM 기반 자율 에이전트의 아키텍처를 코드로 구현하는 방법에 대한 설명을 포함하고 있으며, 추가적인 컨텍스트와 함께 제공됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    result[\"output_text\"]\n",
    ")  # 결과 딕셔너리에서 'output_text' 키에 해당하는 값을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893955a",
   "metadata": {},
   "source": [
    "이 함수는 `result` 딕셔너리의 `'intermediate_steps'` 키에 저장된 리스트에서 처음 세 요소를 선택하고, 이들 사이에 두 줄바꿈(`\\n\\n`)을 삽입하여 연결한 문자열을 출력합니다. 이는 중간 계산 단계나 결과를 시각적으로 구분하여 표시할 때 유용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "519754b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article discusses LLM powered autonomous agents, which are intelligent systems that can perform tasks without human intervention. The agents consist of three main components: planning, memory, and tool use. The planning component involves task decomposition and self-reflection. The memory component includes different types of memory and the use of Maximum Inner Product Search (MIPS). The tool use component is demonstrated through case studies, such as a scientific discovery agent and generative agents simulation. The article also highlights the challenges of implementing LLM powered autonomous agents.\n",
      "\n",
      "이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다.\n",
      "\n",
      "이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714ef0a",
   "metadata": {},
   "source": [
    "## 한 번의 체인으로 분할하고 요약하기\n",
    "\n",
    "편의를 위해, 우리는 긴 문서의 텍스트 분할과 요약을 단일 `AnalyzeDocumentsChain`으로 묶을 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8be11",
   "metadata": {},
   "source": [
    "`AnalyzeDocumentChain` 클래스는 문서 분석 및 요약 작업을 위한 체인을 생성합니다. 이 예제에서는 `AnalyzeDocumentChain` 인스턴스를 생성하고, `combine_docs_chain`과 `text_splitter`를 인자로 전달하여 초기화합니다. 이후, 첫 번째 문서(`docs[0]`)의 `page_content`를 사용하여 문서 요약 프로세스를 실행합니다. 이 과정은 문서의 내용을 분석하고 요약하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92a7327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article discusses LLM powered autonomous agents, which are intelligent systems that can perform tasks without human intervention. The agents consist of three main components: planning, memory, and tool use. The planning component involves task decomposition and self-reflection. The memory component includes different types of memory and the use of Maximum Inner Product Search (MIPS). The tool use component is demonstrated through case studies, such as a scientific discovery agent and generative agents simulation. The article also highlights the challenges of implementing LLM powered autonomous agents.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수 있다. Reflexion 프레임워크는 효율적이지 않거나 환각을 포함하는 궤적을 중지해야 할 때 휴리스틱 함수를 사용한다. 비효율적인 계획은 성공하지 못한 상태에서 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 행동 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 시도 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍으로 구성되도록 한다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수 있다. Reflexion 프레임워크는 효율적이지 않거나 환각을 포함하는 궤적을 중지해야 할 때 휴리스틱 함수를 사용한다. 비효율적인 계획은 성공하지 못한 상태에서 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 행동 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 시도 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍으로 구성되도록 한다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수 있다. Reflexion 프레임워크는 효율적이지 않거나 환각을 포함하는 궤적을 중지해야 할 때 휴리스틱 함수를 사용한다. 비효율적인 계획은 성공하지 못한 상태에서 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 행동 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 시도 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍으로 구성되도록 한다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. 또한, Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 이전의 출력 시퀀스를 피드백과 함께 명시적으로 제시하여 모델이 스스로 개선할 수 있도록 한다. 이를 통해 모델은 피드백 시퀀스를 기반으로 자기 반성하여 더 나은 출력을 생성할 수 있다. 모델은 테스트 시에 인간 주석자와 함께 여러 라운드의 지침을 선택적으로 받을 수도 있다.이 기사는 인간의 개입 없이 작업을 수행할 수 있는 지능형 시스템인 LLM 기반 자율 에이전트에 대해 논의한다. 에이전트는 계획, 기억 및 도구 사용이라는 세 가지 주요 구성 요소로 구성된다. 계획 구성 요소는 작업 분해와 자기 반성을 포함한다. 기억 구성 요소에는 다양한 유형의 기억과 최대 내적 제품 검색(MIPS)의 사용이 포함된다. 도구 사용 구성 요소는 과학적 발견 에이전트 및 생성 에이전트 시뮬레이션과 같은 사례 연구를 통해 시연된다. 이 기사는 또한 LLM 기반 자율 에이전트를 구현하는 데 직면하는 도전과제를 강조한다. 에이전트는 단기 기억과 장기 기억을 활용하여 학습하며, 외부 API를 호출하여 추가 정보를 얻고, 모델 가중치 이후에 변경하기 어려운 현재 정보, 코드 실행 능력, 독점 정보 소스에 접근하는 등의 기능을 갖추게 된다. 또한, 복잡한 작업을 수행하기 위해 에이전트는 작업 분해를 통해 단계별로 생각하고 모델의 사고 과정을 이해하는 데 도움이 되는 체인 오브 씨피롤링(CoT) 기법을 사용한다. CoT는 큰 작업을 여러 개의 관리 가능한 작업으로 분해하여 모델의 성능을 향상시키는 데 도움이 된다. 또한, Tree of Thoughts (Yao et al. 2023)는 CoT를 확장하여 각 단계에서 여러 가지 추론 가능성을 탐색한다. 이는 문제를 여러 단계로 분해하고 각 단계마다 여러 가지 생각을 생성하여 트리 구조를 만든다. 검색 과정은 각 상태가 분류기(프롬프트를 통해) 또는 다수결 투표에 의해 평가되는 BFS(너비 우선 탐색) 또는 DFS(깊이 우선 탐색)일 수 있다. 작업 분해는 (1) \"XYZ를 위한 단계.\\n1.\"과 같은 간단한 프롬프트를 사용하여 LLM에 의해 수행될 수 있으며, (2) 작업별 지침을 사용하여 수행될 수 있으며, 예를 들어 소설 작성을 위해 \"이야기 개요를 작성하십시오.\"라고 할 수 있으며, (3) 인간의 입력을 사용하여 수행될 수 있다. 또한, LLM+P (Liu et al. 2023)라는 다른 접근 방식은 외부 고전적인 계획자를 활용하여 장기 계획을 수행한다. 이 접근 방식은 계획 단계를 외부 도구에 위탁하며, 도메인 특정 PDDL과 적합한 계획자의 가용성을 가정한다. 자기 반성은 자율 에이전트가 과거의 행동 결정을 개선하고 이전의 실수를 수정함으로써 반복적으로 발전할 수 있도록 하는 중요한 측면이다. 이는 시행착오가 불가피한 실제 작업에서 중요한 역할을 한다. ReAct (Yao et al. 2023)는 LLM 내에서 추론과 행동을 통합하여 작업 공간을 과업별 이산적 행동과 언어 공간의 조합으로 확장한다. 이를 통해 LLM은 환경과 상호작용할 수 있게 되며(예: Wikipedia 검색 API 사용), 동시에 LLM에게 추론 트레이스를 자연어로 생성하도록 유도한다. ReAct 프롬프트 템플릿은 LLM이 생각하는 과정을 명시적으로 단계별로 포맷팅한 것이다. 또한, 지식 집약적 작업과 의사 결정 작업에 대한 실험에서 ReAct는 Thought: ... 단계가 제거된 Act-only 기준보다 더 잘 작동한다. Reflexion (Shinn & Labash 2023)은 동적 기억과 자기 반성 능력을 갖춘 에이전트에게 추론 기술을 개선하기 위한 프레임워크를 제공한다. Reflexion은 간단한 이진 보상을 제공하는 보상 모델과 ReAct의 설정을 따르는 작업별 행동 공간을 가지는 표준 RL 설정을 갖추고 있다. 각 행동 $a_t$ 후, 에이전트는 휴리스틱 $h_t$를 계산하고 자기 반성 결과에 따라 환경을 재설정하여 새로운 시도를 시작할 수 있다. Reflexion 프레임워크는 효율적이지 않거나 환각을 포함하는 궤적을 중지해야 할 때 휴리스틱 함수를 사용한다. 비효율적인 계획은 성공하지 못한 상태에서 너무 오래 걸리는 궤적을 의미한다. 환각은 환경에서 동일한 관찰로 이어지는 연속적인 동일한 행동 순서를 만나는 것으로 정의된다. 자기 반성은 LLM에게 두 번의 시도 예제를 보여주어 각 예제가 (실패한 궤적, 계획의 미래 변경을 안내하기 위한 이상적인 반성)의 쌍으로 구성되도록 한다. 그런 다음 반성은 LLM에게 쿼리할 때 사용되는 작업 메모리에 최대 세 개까지 추가된다. 또한, AlfWorld Env와 HotpotQA에서의 실험 결과, AlfWorld에서는 비효율적인 계획보다 환각이 더 일반적인 실패로 나타났다. 또한, Chain of Hindsight (CoH; Liu et al. 2023)는 모델에게 이전의 출력 시퀀스를 피드백과 함께 명시적으로 제시하여 모델이 스스로 개선할 수 있도록 한다. 이를 통해 모델은 피드백 시퀀스를 기반으로 자기 반성하여 더 나은 출력을 생성할 수 있다. 모델은 테스트 시에 인간 주석자와 함께 여러 라운드의 지침을 선택적으로 받을 수도 있다. 또한, CoH는 오버피팅을 피하기 위해 사전 훈련 데이터셋의 로그 우도를 최대화하기 위한 정규화 항을 추가CoH는 모델이 점진적으로 개선된 출력을 생성하기 위해 개선된 출력의 연속적인 히스토리를 제시하고 모델을 해당 추세를 따르도록 훈련시키는 아이디어이다. AD(Algorithm Distillation; Laskin et al. 2023)는 이와 같은 아이디어를 강화 학습 작업의 교차 에피소드 궤적에 적용하는데, 여기서 알고리즘은 긴 히스토리에 의존하는 정책으로 캡슐화된다. 에이전트가 여러 번 환경과 상호작용하고 각 에피소드에서 약간씩 개선되는 것을 고려할 때, AD는 이러한 학습 히스토리를 연결하여 모델에 입력으로 제공한다. 따라서 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 기대할 수 있다. 이는 과제별 정책을 훈련시키는 것이 아닌 강화 학습 과정 자체를 학습하는 것을 목표로 한다.CoH는 모델이 점진적으로 개선된 출력을 생성하기 위해 개선된 출력의 연속적인 히스토리를 제시하고 모델을 해당 추세를 따르도록 훈련시키는 아이디어이다. AD(Algorithm Distillation; Laskin et al. 2023)는 이와 같은 아이디어를 강화 학습 작업의 교차 에피소드 궤적에 적용하는데, 여기서 알고리즘은 긴 히스토리에 의존하는 정책으로 캡슐화된다. 에이전트가 여러 번 환경과 상호작용하고 각 에피소드에서 약간씩 개선되는 것을 고려할 때, AD는 이러한 학습 히스토리를 연결하여 모델에 입력으로 제공한다. 따라서 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 기대할 수 있다. 이는 과제별 정책을 훈련시키는 것이 아닌 강화 학습 과정 자체를 학습하는 것을 목표로 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다고 가설을 세우고 있다. 훈련 단계에서 각 RL 실행 중에는 무작위 작업이 샘플링되고, 다중 에피소드 히스토리의 부분 수열이 훈련에 사용되며, 학습된 정책은 작업에 독립적이다. 실제로 모델은 제한된 문맥 창 길이를 가지므로 에피소드는 다중 에피소드 히스토리를 구성하기에 충분히 짧아야 한다. 2-4 에피소드의 다중 에피소드 문맥은 거의 최적인 문맥 내 강화 학습 알고리즘을 학습하는 데 필요하다. 문맥 내 강화 학습의 등장은 충분히 긴 문맥이 필요하다.CoH는 모델이 점진적으로 개선된 출력을 생성하기 위해 개선된 출력의 연속적인 히스토리를 제시하고 모델을 해당 추세를 따르도록 훈련시키는 아이디어이다. AD(Algorithm Distillation; Laskin et al. 2023)는 이와 같은 아이디어를 강화 학습 작업의 교차 에피소드 궤적에 적용하는데, 여기서 알고리즘은 긴 히스토리에 의존하는 정책으로 캡슐화된다. 에이전트가 여러 번 환경과 상호작용하고 각 에피소드에서 약간씩 개선되는 것을 고려할 때, AD는 이러한 학습 히스토리를 연결하여 모델에 입력으로 제공한다. 따라서 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 기대할 수 있다. 이는 과제별 정책을 훈련시키는 것이 아닌 강화 학습 과정 자체를 학습하는 것을 목표로 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다고 가설을 세우고 있다. 훈련 단계에서 각 RL 실행 중에는 무작위 작업이 샘플링되고, 다중 에피소드 히스토리의 부분 수열이 훈련에 사용되며, 학습된 정책은 작업에 독립적이다. 실제로 모델은 제한된 문맥 창 길이를 가지므로 에피소드는 다중 에피소드 히스토리를 구성하기에 충분히 짧아야 한다. 2-4 에피소드의 다중 에피소드 문맥은 거의 최적인 문맥 내 강화 학습 알고리즘을 학습하는 데 필요하다. 문맥 내 강화 학습의 등장은 충분히 긴 문맥이 필요하다. AD는 ED (expert distillation), source policy, RL^2와 비교하여 성능이 가까워지는 동시에 오프라인 강화 학습만 사용하므로 다른 기준선보다 훨씬 빠르게 학습한다. 또한 소스 정책의 부분 훈련 히스토리에 의존할 때, AD는 ED 기준선보다 훨씬 빠르게 개선된다.CoH는 모델이 점진적으로 개선된 출력을 생성하기 위해 개선된 출력의 연속적인 히스토리를 제시하고 모델을 해당 추세를 따르도록 훈련시키는 아이디어이다. AD(Algorithm Distillation; Laskin et al. 2023)는 이와 같은 아이디어를 강화 학습 작업의 교차 에피소드 궤적에 적용하는데, 여기서 알고리즘은 긴 히스토리에 의존하는 정책으로 캡슐화된다. 에이전트가 여러 번 환경과 상호작용하고 각 에피소드에서 약간씩 개선되는 것을 고려할 때, AD는 이러한 학습 히스토리를 연결하여 모델에 입력으로 제공한다. 따라서 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 기대할 수 있다. 이는 과제별 정책을 훈련시키는 것이 아닌 강화 학습 과정 자체를 학습하는 것을 목표로 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다고 가설을 세우고 있다. 훈련 단계에서 각 RL 실행 중에는 무작위 작업이 샘플링되고, 다중 에피소드 히스토리의 부분 수열이 훈련에 사용되며, 학습된 정책은 작업에 독립적이다. 실제로 모델은 제한된 문맥 창 길이를 가지므로 에피소드는 다중 에피소드 히스토리를 구성하기에 충분히 짧아야 한다. 2-4 에피소드의 다중 에피소드 문맥은 거의 최적인 문맥 내 강화 학습 알고리즘을 학습하는 데 필요하다. 문맥 내 강화 학습의 등장은 충분히 긴 문맥이 필요하다. AD는 ED (expert distillation), source policy, RL^2와 비교하여 성능이 가까워지는 동시에 오프라인 강화 학습만 사용하므로 다른 기준선보다 훨씬 빠르게 학습한다. 또한 소스 정책의 부분 훈련 히스토리에 의존할 때, AD는 ED 기준선보다 훨씬 빠르게 개선된다. AD는 기억의 종류 중 하나인 감각 기억을 포함하여 인간의 뇌에서 다양한 종류의 기억이 있다.CoH는 모델이 점진적으로 개선된 출력을 생성하기 위해 개선된 출력의 연속적인 히스토리를 제시하고 모델을 해당 추세를 따르도록 훈련시키는 아이디어이다. AD(Algorithm Distillation; Laskin et al. 2023)는 이와 같은 아이디어를 강화 학습 작업의 교차 에피소드 궤적에 적용하는데, 여기서 알고리즘은 긴 히스토리에 의존하는 정책으로 캡슐화된다. 에이전트가 여러 번 환경과 상호작용하고 각 에피소드에서 약간씩 개선되는 것을 고려할 때, AD는 이러한 학습 히스토리를 연결하여 모델에 입력으로 제공한다. 따라서 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 기대할 수 있다. 이는 과제별 정책을 훈련시키는 것이 아닌 강화 학습 과정 자체를 학습하는 것을 목표로 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다고 가설을 세우고 있다. 훈련 단계에서 각 RL 실행 중에는 무작위 작업이 샘플링되고, 다중 에피소드 히스토리의 부분 수열이 훈련에 사용되며, 학습된 정책은 작업에 독립적이다. 실제로 모델은 제한된 문맥 창 길이를 가지므로 에피소드는 다중 에피소드 히스토리를 구성하기에 충분히 짧아야 한다. 2-4 에피소드의 다중 에피소드 문맥은 거의 최적인 문맥 내 강화 학습 알고리즘을 학습하는 데 필요하다. 문맥 내 강화 학습의 등장은 충분히 긴 문맥이 필요하다. AD는 ED (expert distillation), source policy, RL^2와 비교하여 성능이 가까워지는 동시에 오프라인 강화 학습만 사용하므로 다른 기준선보다 훨씬 빠르게 학습한다. 또한 소스 정책의 부분 훈련 히스토리에 의존할 때, AD는 ED 기준선보다 훨씬 빠르게 개선된다. AD는 기억의 종류 중 하나인 감각 기억을 포함하여 인간의 뇌에서 다양한 종류의 기억이 있다. 인간의 기억은 단기 기억과 장기 기억으로 나눌 수 있으며, 장기 기억은 명시적 기억과 암시적 기억으로 구분된다. 명시적 기억은 사실과 사건에 대한 기억이며, 암시적 기억은 무의식적으로 수행되는 기술과 루틴을 포함한다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH (Locality-Sensitive Hashing)은 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY (Approximate Nearest Neighbors Oh Yeah)는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. 이는 입력 공간을 반으로 나누는 하이퍼플레인을 나타내는 비단말 노드가 있는 이진 트리의 집합이다. 각 리프는 하나의 데이터 포인트를 저장한다. ANNOY 검색은 모든 트리에서 진행되어 쿼리에 가장 가까운 반을 반복적으로 검색하고 결과를 집계한다. 이 아이디어는 KD 트리와 관련이 있지만 훨씬 확장 가능하다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH (Locality-Sensitive Hashing)은 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY (Approximate Nearest Neighbors Oh Yeah)는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. 이는 입력 공간을 반으로 나누는 하이퍼플레인을 나타내는 비단말 노드가 있는 이진 트리의 집합이다. 각 리프는 하나의 데이터 포인트를 저장한다. ANNOY 검색은 모든 트리에서 진행되어 쿼리에 가장 가까운 반을 반복적으로 검색하고 결과를 집계한다. 이 아이디어는 KD 트리와 관련이 있지만 훨씬 확장 가능하다. HNSW (Hierarchical Navigable Small World)는 소셜 네트워크의 \"육도 분리\" 기능과 같이 대부분의 노드가 작은 단계로 다른 노드에 도달할 수 있는 작은 세계 네트워크 개념에서 영감을 받았다. HNSW는 이러한 작은 세계 그래프의 계층적인 레이어를 구축하며, 하단 레이어에는 실제 데이터 포인트가 포함된다. 중간 레이어는 검색 속도를 높이기 위해 바로 가기를 생성한다. HNSW는 검색을 수행할 때 상위 레이어의 임의의 노드에서 시작하여 목표로 이동한다. 더 이상 가까워질 수 없을 때 다음 레이어로 이동하고, 하단 레이어에 도달할 때까지 이동한다. 상위 레이어의 각 이동은 데이터 공간에서 큰 거리를 이동할 수 있으며, 하단 레이어의 각 이동은 검색 품질을 개선한다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH는 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. HNSW는 소셜 네트워크의 \"육도 분리\" 기능과 같이 대부분의 노드가 작은 단계로 다른 노드에 도달할 수 있는 작은 세계 네트워크 개념에서 영감을 받았다. HNSW는 이러한 작은 세계 그래프의 계층적인 레이어를 구축하며, 하단 레이어에는 실제 데이터 포인트가 포함된다. 중간 레이어는 검색 속도를 높이기 위해 바로 가기를 생성한다. HNSW는 검색을 수행할 때 상위 레이어의 임의의 노드에서 시작하여 목표로 이동한다. 더 이상 가까워질 수 없을 때 다음 레이어로 이동하고, 하단 레이어에 도달할 때까지 이동한다. 상위 레이어의 각 이동은 데이터 공간에서 큰 거리를 이동할 수 있으며, 하단 레이어의 각 이동은 검색 품질을 개선한다. FAISS는 고차원 공간에서 노드 간의 거리가 가우시안 분포를 따르고 데이터 포인트의 군집화가 존재한다는 가정에 기반하여 작동한다. FAISS는 벡터 양자화를 적용하여 벡터 공간을 군집으로 분할하고, 군집 내에서 양자화를 더 세밀하게 조정한다. 검색은 먼저 거친 양자화로 군집 후보를 찾은 다음, 더 세밀한 양자화로 각 군집을 자세히 살펴본다. ScaNN의 주요 개념은 이방성 벡터 양자화이다. ScaNN은 데이터 포인트 $x_i$를 $\\tilde{x}_i$로 양자화하는데, 이 때 내적 $\\langle q, x_i \\rangle$가 가능한한 $\\angle q, \\tilde{x}_i$의 원래 거리와 유사하도록 한다. 이는 가장 가까운 양자화 중심점을 선택하는 대신에 이루어진다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH는 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. HNSW는 소셜 네트워크의 \"육도 분리\" 기능과 같이 대부분의 노드가 작은 단계로 다른 노드에 도달할 수 있는 작은 세계 네트워크 개념에서 영감을 받았다. HNSW는 이러한 작은 세계 그래프의 계층적인 레이어를 구축하며, 하단 레이어에는 실제 데이터 포인트가 포함된다. 중간 레이어는 검색 속도를 높이기 위해 바로 가기를 생성한다. HNSW는 검색을 수행할 때 상위 레이어의 임의의 노드에서 시작하여 목표로 이동한다. 더 이상 가까워질 수 없을 때 다음 레이어로 이동하고, 하단 레이어에 도달할 때까지 이동한다. 상위 레이어의 각 이동은 데이터 공간에서 큰 거리를 이동할 수 있으며, 하단 레이어의 각 이동은 검색 품질을 개선한다. FAISS는 고차원 공간에서 노드 간의 거리가 가우시안 분포를 따르고 데이터 포인트의 군집화가 존재한다는 가정에 기반하여 작동한다. FAISS는 벡터 양자화를 적용하여 벡터 공간을 군집으로 분할하고, 군집 내에서 양자화를 더 세밀하게 조정한다. 검색은 먼저 거친 양자화로 군집 후보를 찾은 다음, 더 세밀한 양자화로 각 군집을 자세히 살펴본다. ScaNN의 주요 개념은 이방성 벡터 양자화이다. ScaNN은 데이터 포인트 $x_i$를 $\\tilde{x}_i$로 양자화하는데, 이 때 내적 $\\langle q, x_i \\rangle$가 가능한한 $\\angle q, \\tilde{x}_i$의 원래 거리와 유사하도록 한다. 이는 가장 가까운 양자화 중심점을 선택하는 대신에 이루어진다. LLMs에 외부 도구를 제공함으로써 모델의 능력을 크게 확장할 수 있다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH는 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. HNSW는 소셜 네트워크의 \"육도 분리\" 기능과 같이 대부분의 노드가 작은 단계로 다른 노드에 도달할 수 있는 작은 세계 네트워크 개념에서 영감을 받았다. HNSW는 이러한 작은 세계 그래프의 계층적인 레이어를 구축하며, 하단 레이어에는 실제 데이터 포인트가 포함된다. 중간 레이어는 검색 속도를 높이기 위해 바로 가기를 생성한다. HNSW는 검색을 수행할 때 상위 레이어의 임의의 노드에서 시작하여 목표로 이동한다. 더 이상 가까워질 수 없을 때 다음 레이어로 이동하고, 하단 레이어에 도달할 때까지 이동한다. 상위 레이어의 각 이동은 데이터 공간에서 큰 거리를 이동할 수 있으며, 하단 레이어의 각 이동은 검색 품질을 개선한다. FAISS는 고차원 공간에서 노드 간의 거리가 가우시안 분포를 따르고 데이터 포인트의 군집화가 존재한다는 가정에 기반하여 작동한다. FAISS는 벡터 양자화를 적용하여 벡터 공간을 군집으로 분할하고, 군집 내에서 양자화를 더 세밀하게 조정한다. 검색은 먼저 거친 양자화로 군집 후보를 찾은 다음, 더 세밀한 양자화로 각 군집을 자세히 살펴본다. ScaNN의 주요 개념은 이방성 벡터 양자화이다. ScaNN은 데이터 포인트 $x_i$를 $\\tilde{x}_i$로 양자화하는데, 이 때 내적 $\\langle q, x_i \\rangle$가 가능한한 $\\angle q, \\tilde{x}_i$의 원래 거리와 유사하도록 한다. 이는 가장 가까운 양자화 중심점을 선택하는 대신에 이루어진다. LLMs에 외부 도구를 제공함으로써 모델의 능력을 크게 확장할 수 있다. MRKL (Karpas et al. 2022)는 자율 에이전트를 위한 신경 기호 아키텍처로, \"전문가\" 모듈의 컬렉션과 일반적인 목적의 LLM이라는 라우터로 구성된다. 이러한 모듈은 신경망 (예: 딥러닝 모델) 또는 심볼릭 (예: 수학 계산기, 통화 변환기, 날씨 API)일 수 있다.AD는 모델의 출력을 개선하기 위해 개선된 출력의 연속적인 히스토리를 활용하여 모델을 훈련시키는 아이디어이다. AD는 강화 학습 작업에서 알고리즘을 사용하여 긴 히스토리에 의존하는 정책을 캡슐화한다. AD는 여러 번의 상호작용을 통해 모델을 개선하는 학습 히스토리를 모델에 입력으로 제공하여 다음 예측된 행동이 이전 시도보다 더 나은 성능을 보이도록 한다. AD는 특정 작업에 대해 훈련된 여러 소스 정책에 의해 생성된 학습 히스토리를 신경망으로 압축할 수 있다는 가설을 세우고 있다. AD는 다른 기준선보다 빠르게 학습하며, 소스 정책의 부분 훈련 히스토리에 의존할 때 더욱 개선된다. 또한 인간의 뇌에서와 같이 AD는 다양한 종류의 기억을 활용하여 모델을 훈련시킨다. LSH는 입력 항목을 동일한 버킷으로 매핑하는 해싱 함수를 도입하여 유사한 항목을 높은 확률로 동일한 버킷에 매핑한다. ANNOY는 핵심 데이터 구조로 랜덤 프로젝션 트리를 사용한다. HNSW는 소셜 네트워크의 \"육도 분리\" 기능과 같이 대부분의 노드가 작은 단계로 다른 노드에 도달할 수 있는 작은 세계 네트워크 개념에서 영감을 받았다. HNSW는 이러한 작은 세계 그래프의 계층적인 레이어를 구축하며, 하단 레이어에는 실제 데이터 포인트가 포함된다. 중간 레이어는 검색 속도를 높이기 위해 바로 가기를 생성한다. HNSW는 검색을 수행할 때 상위 레이어의 임의의 노드에서 시작하여 목표로 이동한다. 더 이상 가까워질 수 없을 때 다음 레이어로 이동하고, 하단 레이어에 도달할 때까지 이동한다. 상위 레이어의 각 이동은 데이터 공간에서 큰 거리를 이동할 수 있으며, 하단 레이어의 각 이동은 검색 품질을 개선한다. FAISS는 고차원 공간에서 노드 간의 거리가 가우시안 분포를 따르고 데이터 포인트의 군집화가 존재한다는 가정에 기반하여 작동한다. FAISS는 벡터 양자화를 적용하여 벡터 공간을 군집으로 분할하고, 군집 내에서 양자화를 더 세밀하게 조정한다. 검색은 먼저 거친 양자화로 군집 후보를 찾은 다음, 더 세밀한 양자화로 각 군집을 자세히 살펴본다. ScaNN의 주요 개념은 이방성 벡터 양자화이다. ScaNN은 데이터 포인트 $x_i$를 $\\tilde{x}_i$로 양자화하는데, 이 때 내적 $\\langle q, x_i \\rangle$가 가능한한 $\\angle q, \\tilde{x}_i$의 원래 거리와 유사하도록 한다. 이는 가장 가까운 양자화 중심점을 선택하는 대신에 이루어진다. LLMs에 외부 도구를 제공함으로써 모델의 능력을 크게 확장할 수 있다. MRKL (Karpas et al. 2022)는 자율 에이전트를 위한 신경 기호 아키텍처로, \"전문가\" 모듈의 컬렉션과 일반적인 목적의 LLM이라는 라우터로 구성된다. 이러한 모듈은 신경망 (예: 딥러닝 모델) 또는 심볼릭 (예: 수학 계산기, 통화 변환기, 날씨 API)일 수 있다. TALM (Tool Augmented Language Models; Parisi et al. 2022)와 Toolformer (Schick et al. 2023)은 외부 도구 API를 사용하는 방법을 학습하기 위해 LM을 세밀하게 조정한다. 새로 추가된 API 호출 주석이 모델 출력의 품질을 개선할 수 있는지 여부에 따라 데이터셋이 확장된다. Prompt Engineering의 \"External APIs\" 섹션에서 자세한 내용을 확인할 수 있다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다:\n",
      "\n",
      "API 호출이 필요한지 여부.\n",
      "호출할 적절한 API 식별: 만족스럽지 않은 경우, LLM은 반복적으로 API 입력을 수정해야 합니다(예: 검색 엔진 API에 대한 검색 키워드 결정).\n",
      "API 결과에 기반한 응답: 결과가 만족스럽지 않은 경우, 모델은 결과를 개선하고 다시 호출할 수 있습니다.\n",
      "\n",
      "이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구했습니다. 이 에이전트는 인터넷을 검색하고 문서를 읽고 코드를 실행하며 로봇 실험 API를 호출하고 다른 LLM을 활용할 수 있습니다. 예를 들어 \"새로운 항암 약물 개발\"이라는 요청을 받았을 때, 모델은 다음과 같은 추론 단계를 제시했습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구했습니다. 이 에이전트는 인터넷을 검색하고 문서를 읽고 코드를 실행하며 로봇 실험 API를 호출하고 다른 LLM을 활용할 수 있습니다. 예를 들어 \"새로운 항암 약물 개발\"이라는 요청을 받았을 때, 모델은 다음과 같은 추론 단계를 제시했습니다. 먼저, 현재 항암 약물 개발의 최신 동향에 대해 알아보기 위해 인터넷 검색을 수행합니다. 그런 다음 특정 대상을 선택하고 이를 타겟으로 하는 화합물을 요청합니다. 화합물이 식별되면, 모델은 그 합성을 시도합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구하였습니다. LLM은 메모리 스트림, 검색 모델 및 반사 메커니즘을 사용하여 에이전트의 행동을 지원합니다. 메모리 스트림은 에이전트의 경험을 기록하는 장기적인 메모리 모듈입니다. 검색 모델은 관련성, 최신성 및 중요성에 따라 에이전트의 행동을 결정하기 위해 컨텍스트를 제공합니다. 반사 메커니즘은 시간에 걸쳐 메모리를 종합하여 미래의 행동을 안내하는 고수준의 요약입니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구하였습니다. LLM은 메모리 스트림, 검색 모델 및 반사 메커니즘을 사용하여 에이전트의 행동을 지원합니다. 메모리 스트림은 에이전트의 경험을 기록하는 장기적인 메모리 모듈입니다. 검색 모델은 관련성, 최신성 및 중요성에 따라 에이전트의 행동을 결정하기 위해ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구하였습니다. LLM은 메모리 스트림, 검색 모델 및 반사 메커니즘을 사용하여 에이전트의 행동을 지원합니다. 메모리 스트림은 에이전트의 경험을 기록하는 장기적인 메모리 모듈입니다. 검색 모델은 관련성, 최신성ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 판단하는 것은 어려울 수 있습니다. Boiko et al. (2023)는 LLM을 사용하여 과학적 발견을 다루기 위한 에이전트를 연구하였습니다. LLM은 메모리 스트림, 검색 모델 및 반사 메커니즘을 사용하여 에이전트의 행동을 지원합니다. 메모리 스트림은 에이전트의 경험을 기록하는 장기적인 메모리 모듈입니다. 검색 모델은 관련성, 최신성, 목표 지향성 등을 고려하여 정보를 검색합니다. 반사 메커니즘은 에이전트가 이전에 수행한 행동을 기반으로 현재 상황을 평가하고 적절한 행동을 선택하는 데 도움을 줍니다. 이러한 기능을 통해 LLMChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형은 AI 어시스턴트가 사용자 요청을 처리하는 데 도움을 주며, 각 작업에는 특정한 인수와 관련된 속성이 있습니다. 이러한 작업 유형을 처리하기 위해서는 AI 어시스턴트가 적절한 모델을 선택하고 실행 결과를 요약하는 능력이 필요합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형은 AI 어시스턴트가 사용자 요청을 처리하는 데 도움을 주며, 각 작업에는 특정한 인수와 관련된 속성이 있습니다. 이러한 작업 유형을 처리하기 위해서는 AI 어시스턴트가 적절한 모델을 선택하고 실행 결과를 요약하는 능력이 필요합니다. AI 어시스턴트는 작업을 수행한 후 결과를 사용자에게 제시하고ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 메서드의 이름을 나열하고, 각 파일의 내용을 모두 출력해야 합니다. 각 파일은 markdown 코드 블록 형식을 따라야 하며, 다음 토큰을 대체해야 합니다: FILENAME, LANG, CODE. 또한, \"entrypoint\" 파일부터 시작하여 해당 파일에서 가져온 파일로 이동해야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 메서드의 이름을 나열하고, 각 파일의 내용ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 메서드의 이름을 나열하고, 각 파일의 내용을 나타내는 것이 좋습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 메서드의 이름을 나열하고, 각 파일의 내용을 나타내는 것이 좋습니다. 또한, pytest와 dataclasses에 대한 정보가 추가되었습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 메서드의 이름을 나열하고, 각 파일의 내용을 나타내는 것이 좋습니다. 또한, pytest와 dataclasses에 대한 정보가 추가되었습니다. 이러한 새로운 정보를 고려하여 원래 요약을 수정하였습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어 및 프레임워크에 적합한 파일 네이밍 규칙을 따르며, 코드가 완전하고 기능적인지 확인해야 합니다. 또한, 파일 간의 호환성을 보장하고, 필요한 경우 모듈 종속성이나 패ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어 및 프레임워크에 적합한 파일 네이밍 규칙을 따르며, 코드가 완전하고 기능적인지 확인해야 합니다. 또한, 파일 간의 호환성을 보장하고, 필요한 경우 모듈 종속성이나 패키지/프로젝트로 작성된 코드를 설명하는 것이 좋습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어 모델과 다른 파일 간의 호환성을 확인해야 합니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\", \"send_tweet\", \"do_nothing\", \"task_complete\"와 같은 추가적인 작업 유형이 소개되었습니다. 이러한 작업 유형에 대한 자세한 설명이 필요합니다. 시작하기 전에 각 파일의 핵심 클래스, 함수, 모듈 및 종속성을 확인하고, 언어 모델과 다른 파일 간의 호환성을 확인해야 합니다. ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\",ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다. 이러한 작업은 LLM의 다양한 도구 사용 능력을 보여주는 예시입니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다. 이러한 작업은 LLM의 다양한 도구 사용 능력을 보여주는 예시입니다. 또한, Joon Sung Park 등은 \"Generative Agents: Interactive Simulacra of Human Behavior\"에서 인간 행동의 상호작용적인 시뮬라크인 생성 에이전트에 대해 연구하였습니다. AutoGPT와 GPT-Engineer는 ChatGPT를 개선하기 위한 프로젝트입니다.ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다. 이러한 작업은 LLM의 다양한 도구 사용 능력을 보여주는 예시입니다. 또한, Joon Sung Park 등은 \"Generative Agents: Interactive Simulacra of Human Behavior\"에서 인간 행동의 상호작용적인 시뮬라크인 생성 에이전트에 대해 연구하였습니다. AutoGPT와 GPT-Engineer는 ChatGPT를 개선하기 위한 프로젝트입니다. Prompt Engineering은 LLM의 성능을 향상시키기 위한 방법 중 하나입니다."
     ]
    }
   ],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "# AnalyzeDocumentChain 인스턴스를 생성합니다. 이때, combine_docs_chain과 text_splitter를 인자로 전달합니다.\n",
    "summarize_document_chain = AnalyzeDocumentChain(\n",
    "    combine_docs_chain=chain, text_splitter=text_splitter\n",
    ")\n",
    "# 첫 번째 문서의 페이지 내용을 사용하여 문서 요약 프로세스를 실행합니다.\n",
    "summarized_result = summarize_document_chain.invoke(\n",
    "    {\"input_document\": docs[0].page_content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfb17a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 플러그인과 OpenAI API 함수 호출은 실제로 작동하는 도구 사용 능력이 강화된 LLM의 좋은 예입니다. 도구 API의 컬렉션은 다른 개발자(플러그인의 경우) 또는 자체 정의(함수 호출의 경우)로 제공될 수 있습니다. HuggingGPT는 (Shen et al. 2023)에서 ChatGPT를 작업 계획자로 사용하여 HuggingFace 플랫폼에서 사용 가능한 모델을 선택하고 실행 결과에 기반하여 응답을 요약하는 프레임워크입니다. HuggingGPT 시스템은 4단계로 구성되어 있습니다. 첫 번째 단계는 작업 계획으로, LLM이 사용자 요청을 여러 작업으로 파싱합니다. 각 작업에는 작업 유형, ID, 종속성 및 인수와 관련된 네 가지 속성이 있습니다. LLM은 few-shot 예제를 사용하여 작업 파싱과 계획을 수행하는 데 도움을 받습니다. AI 어시스턴트는 사용자 입력을 여러 작업으로 파싱할 수 있으며, 작업은 작업 유형, ID, 종속성 및 인수와 관련된 속성을 가지고 있습니다. 작업 간에는 논리적인 관계가 있으며, 작업 순서를 유의해야 합니다. 사용자 입력을 파싱할 수 없는 경우 빈 JSON으로 응답해야 합니다. LLM은 모델 선택 단계에서 전문 모델에 작업을 분배하고, 요청을 다중 선택 질문으로 구성합니다. LLM은 선택할 수 있는 모델 목록을 제시받습니다. 제한된 문맥 길이로 인해 작업 유형에 기반한 필터링이 필요합니다. AI 어시스턴트는 사용자 요청을 처리하기 위해 모델 목록에서 적합한 모델을 선택하는 데 도움을 줍니다. AI 어시스턴트는 가장 적합한 모델의 모델 ID만 출력합니다. 출력은 엄격한 JSON 형식이어야 하며, \"id\": \"id\", \"reason\": \"선택 이유에 대한 자세한 설명\"과 같은 형식을 따라야 합니다. AI 어시스턴트는 사용자의 요청에 직접적으로 응답한 후, 작업 과정을 설명하고 분석 및 모델 추론 결과를 사용자에게 제시해야 합니다. 추론 결과에 파일 경로가 포함된 경우, 사용자에게 완전한 파일 경로를 알려주어야 합니다. HuggingGPT를 실제 환경에서 사용하기 위해서는 몇 가지 문제를 해결해야 합니다. 첫째, LLM 추론 라운드와 다른 모델과의 상호작용이 프로세스를 느리게 만드는 효율성 개선이 필요합니다. 둘째, 복잡한 작업 내용을 전달하기 위해 긴 문맥 창을 필요로 합니다. 셋째, LLM 출력과 외부 모델 서비스의 안정성을 개선해야 합니다. API-Bank (Li et al. 2023)은 도구 강화된 LLM의 성능을 평가하기 위한 벤치마크입니다. 이 벤치마크에는 53개의 일반적으로 사용되는 API 도구, 완전한 도구 강화된 LLM 워크플로우 및 568개의 API 호출이 포함된 264개의 주석이 달린 대화가 포함되어 있습니다. API의 선택은 검색 엔진, 계산기, 캘린더 쿼리, 스마트 홈 제어, 일정 관리, 건강 데이터 관리, 계정 인증 워크플로우 등 다양한 API를 포함하고 있습니다. 많은 수의 API가 있기 때문에, LLM은 먼저 API 검색 엔진에 접근하여 호출할 적절한 API를 찾은 다음 해당 문서를 사용하여 호출합니다. API-Bank 워크플로우에서 LLM은 몇 가지 결정을 내려야 합니다. 각 단계에서 결정의 정확성을 평가할 수 있습니다. 이 결정에는 다음이 포함됩니다: API 호출이 필요한지 여부, 호출할 적절한 API 식별, API 결과에 기반한 응답. 이 벤치마크는 에이전트의 도구 사용 능력을 세 가지 수준에서 평가합니다. Level-1은 API 호출 능력을 평가하며, Level-2는 API 검색 능력을, Level-3은 API 검색과 호출 이상의 계획 능력을 평가합니다. ChemCrow (Bran et al. 2023)는 LLM이 유기 합성, 약물 개발 및 재료 설계와 같은 작업을 수행하기 위해 13개의 전문가가 설계한 도구로 보강된 도메인 특정 예입니다. LangChain에서 구현된 워크플로우는 이전에 설명한 ReAct와 MRKLs를 결합한 CoT 추론과 작업에 관련된 도구를 결합합니다. LLM은 도구 이름 목록, 유틸리티 설명 및 예상 입력/출력에 대한 세부 정보를 제공받습니다. 그런 다음 필요한 경우 도구를 사용하여 사용자가 제공한 프롬프트에 답변하도록 지시됩니다. 지시는 ReAct 형식을 따르도록 모델에게 알려줍니다 - 생각, 동작, 동작 입력, 관찰. 하지만 LLM을 사용하여 도메인 전문성이 필요한 작업의 성능을 평가할 때, LLM 기반 평가와 전문가 평가의 결과가 다를 수 있습니다. 이는 LLM이 자체적으로 도메인 전문성을 갖지 않기 때문에 발생하는 문제일 수 있습니다. 따라서 LLM을 사용하여 작업 결과의 정확성을 평가할 때는 주의가 필요합니다. 또한, 새로운 context에 따라서 \"improve_code\", \"write_tests\", \"execute_python_file\", \"generate_image\" 등의 작업을 수행할 수 있습니다. 이러한 작업은 LLM의 다양한 도구 사용 능력을 보여주는 예시입니다. 또한, Joon Sung Park 등은 \"Generative Agents: Interactive Simulacra of Human Behavior\"에서 인간 행동의 상호작용적인 시뮬라크인 생성 에이전트에 대해 연구하였습니다. AutoGPT와 GPT-Engineer는 ChatGPT를 개선하기 위한 프로젝트입니다. Prompt Engineering은 LLM의 성능을 향상시키기 위한 방법 중 하나입니다.\n"
     ]
    }
   ],
   "source": [
    "print(summarized_result[\"output_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
