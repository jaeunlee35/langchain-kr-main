{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e457291",
   "metadata": {},
   "source": [
    "# RecursiveCharacterTextSplitter\n",
    "\n",
    "이 텍스트 분할기는 일반적인 텍스트에 권장되는 방식입니다.\n",
    "\n",
    "이 분할기는 문자 목록을 매개변수로 받아 동작합니다.\n",
    "\n",
    "분할기는 청크가 충분히 작아질 때까지 주어진 문자 목록의 순서대로 텍스트를 분할하려고 시도합니다.\n",
    "\n",
    "기본 문자 목록은 `[\"\\n\\n\", \"\\n\", \" \", \"\"]`입니다.\n",
    "\n",
    "- **단락** -> **문장** -> **단어** 순서로 재귀적으로 분할합니다.\n",
    "\n",
    "이는 단락(그 다음으로 문장, 단어) 단위가 의미적으로 가장 강하게 연관된 텍스트 조각으로 간주되므로, 가능한 한 함께 유지하려는 효과가 있습니다.\n",
    "\n",
    "1. 텍스트가 분할되는 방식: 문자 목록(`[\"\\n\\n\", \"\\n\", \" \", \"\"]`) 에 의해 분할됩니다.\n",
    "\n",
    "2. 청크 크기가 측정되는 방식: 문자 수에 의해 측정됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713b32",
   "metadata": {},
   "source": [
    "- `appendix-keywords.txt` 파일을 열어 내용을 읽어들입니다.\n",
    "- 읽어들인 내용을 `file` 변수에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91db2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appendix-keywords.txt 파일을 열어서 f라는 파일 객체를 생성합니다.\n",
    "with open(\"./data/appendix-keywords.txt\") as f:\n",
    "    file = f.read()  # 파일의 내용을 읽어서 file 변수에 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef18d9d",
   "metadata": {},
   "source": [
    "파일로부터 읽은 파일의 일부 내용을 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7163a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "\n",
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "\n",
      "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
      "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어\n"
     ]
    }
   ],
   "source": [
    "# 파일으로부터 읽은 내용을 일부 출력합니다.\n",
    "print(file[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbeb96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995282c",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter`를 사용하여 텍스트를 작은 청크로 분할하는 예제입니다.\n",
    "\n",
    "- `chunk_size`를 250 으로 설정하여 각 청크의 크기를 제한합니다.\n",
    "- `chunk_overlap`을 50 으로 설정하여 인접한 청크 간에 50 개 문자의 중첩을 허용합니다.\n",
    "- `length_function`으로 `len` 함수를 사용하여 텍스트의 길이를 계산합니다.\n",
    "- `is_separator_regex`를 `False`로 설정하여 구분자로 정규식을 사용하지 않습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb43146",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # 청크 크기를 매우 작게 설정합니다. 예시를 위한 설정입니다.\n",
    "    chunk_size=250,\n",
    "    # 청크 간의 중복되는 문자 수를 설정합니다.\n",
    "    chunk_overlap=50,\n",
    "    # 문자열 길이를 계산하는 함수를 지정합니다.\n",
    "    length_function=len,\n",
    "    # 구분자로 정규식을 사용할지 여부를 설정합니다.\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd33f2",
   "metadata": {},
   "source": [
    "- `text_splitter`를 사용하여 `file` 텍스트를 문서 단위로 분할합니다.\n",
    "- 분할된 문서는 `texts` 리스트에 저장됩니다.\n",
    "- `print(texts[0])`과 `print(texts[1])`을 통해 분할된 문서의 첫 번째와 두 번째 문서를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d62b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding'\n",
      "============================================================\n",
      "page_content='Embedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken'\n"
     ]
    }
   ],
   "source": [
    "# text_splitter를 사용하여 file 텍스트를 문서로 분할합니다.\n",
    "texts = text_splitter.create_documents([file])\n",
    "print(texts[0])  # 분할된 문서의 첫 번째 문서를 출력합니다.\n",
    "print(\"===\" * 20)\n",
    "print(texts[1])  # 분할된 문서의 두 번째 문서를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4618a",
   "metadata": {},
   "source": [
    "`text_splitter.split_text()` 함수를 사용하여 `file` 텍스트를 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0097650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding',\n",
       " 'Embedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트를 분할하고 분할된 텍스트의 처음 2개 요소를 반환합니다.\n",
    "text_splitter.split_text(file)[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
