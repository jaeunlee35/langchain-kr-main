{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23050dbd",
   "metadata": {},
   "source": [
    "# Hugging Face\n",
    "\n",
    "Hugging Face Embedding 클래스를 로드해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf71358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b31c9",
   "metadata": {},
   "source": [
    "- `HuggingFaceEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fadfd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3d316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 사용자로부터 HuggingFace Inference API 키를 입력받습니다.\n",
    "inference_api_key = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafd3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스 모델/토크나이저를 다운로드 받을 경로\n",
    "# (예시)\n",
    "\n",
    "import os\n",
    "\n",
    "# ./cache/ 경로에 다운로드 받도록 설정\n",
    "os.environ[\"HF_HOME\"] = \"./cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c600022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceBgeEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b6b99",
   "metadata": {},
   "source": [
    "`HuggingFaceEmbeddings` 클래스를 사용하여 임베딩 객체를 생성합니다.\n",
    "\n",
    "- 이 클래스는 Hugging Face의 Transformers 라이브러리에서 제공하는 사전 훈련된 언어 모델을 활용하여 텍스트 임베딩을 생성합니다.\n",
    "- 생성된 `embeddings` 객체는 텍스트를 벡터 표현으로 변환하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0ce876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teddy/miniconda3/envs/py-test/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()  # HuggingFace 임베딩을 생성합니다.\n",
    "embeddings = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbe067",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9794d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3928f021",
   "metadata": {},
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "- `text` 매개변수로 전달된 텍스트를 임베딩 모델에 입력하여 벡터 표현을 생성합니다.\n",
    "- 생성된 임베딩 벡터는 `query_result` 변수에 저장됩니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적 유사성을 계산하거나 검색에 활용할 수 있는 벡터 표현을 얻는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d73dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0956b",
   "metadata": {},
   "source": [
    "`query_result[:3]`은 `query_result` 리스트의 처음 3개 요소를 슬라이싱(slicing)하여 선택합니다.\n",
    "\n",
    "- 리스트 슬라이싱 문법인 `[start:end]`를 사용하여 `query_result` 리스트의 일부분을 추출합니다.\n",
    "- `start` 인덱스는 포함되고 `end` 인덱스는 제외됩니다. 따라서 `[:3]`은 인덱스 0부터 2까지의 요소를 선택합니다.\n",
    "- 결과적으로 `query_result` 리스트의 첫 번째, 두 번째, 세 번째 요소가 선택됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2612050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032299287617206573, -0.10691168159246445, -0.02121555432677269]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 3개 항목을 선택합니다.\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e588b",
   "metadata": {},
   "source": [
    "`embeddings.embed_documents()` 함수를 사용하여 텍스트 문서를 임베딩합니다.\n",
    "\n",
    "- `[text]`를 인자로 전달하여 단일 문서를 리스트 형태로 임베딩 함수에 전달합니다.\n",
    "- 함수 호출 결과로 반환된 임베딩 벡터를 `doc_result` 변수에 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84da1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents(\n",
    "    [text]\n",
    ")  # 텍스트를 임베딩하여 문서 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc2810",
   "metadata": {},
   "source": [
    "## Hugging Face Inference API\n",
    "\n",
    "Hugging Face Inference API를 통해 임베딩 모델에 접근할 수도 있습니다.\n",
    "\n",
    "이 방법은 sentence_transformers를 설치하거나 모델을 로컬에 다운로드할 필요가 없다는 장점이 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf604c2c",
   "metadata": {},
   "source": [
    "HuggingFaceInferenceAPIEmbeddings를 사용하여 텍스트를 임베딩하는 과정을 보여줍니다.\n",
    "\n",
    "- `HuggingFaceInferenceAPIEmbeddings` 클래스를 초기화할 때 `api_key`와 `model_name`을 전달합니다.\n",
    "  - `api_key`는 Hugging Face Inference API의 인증 키입니다.\n",
    "  - `model_name`은 사용할 임베딩 모델의 이름입니다. 여기서는 \"sentence-transformers/all-MiniLM-l6-v2\" 모델을 사용합니다.\n",
    "- `embed_query` 메서드를 호출하여 주어진 `text`를 임베딩합니다.\n",
    "- 임베딩 결과인 `query_result`의 첫 3개 요소를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fe95ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02381495200097561, 0.08707402646541595, 0.07979416847229004]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    # Hugging Face Inference API 키를 설정합니다.\n",
    "    api_key=inference_api_key,\n",
    "    # 사용할 임베딩 모델의 이름을 지정합니다.\n",
    "    model_name=\"sentence-transformers/all-MiniLM-l6-v2\",\n",
    ")\n",
    "\n",
    "# 주어진 텍스트에 대한 쿼리 임베딩을 생성합니다.\n",
    "query_result = embeddings.embed_query(text)\n",
    "# 쿼리 임베딩 결과의 첫 3개 요소를 가져옵니다.\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073b02e",
   "metadata": {},
   "source": [
    "## Hugging Face Hub\n",
    "\n",
    "Hugging Face Hub 패키지를 통해 로컬에서 임베딩을 생성할 수도 있습니다.\n",
    "\n",
    "이를 위해서는 `huggingface_hub` 패키지를 설치해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d323ff9",
   "metadata": {},
   "source": [
    "huggingface_hub 라이브러리를 설치합니다.\n",
    "\n",
    "- !pip install 명령어를 사용하여 huggingface_hub 라이브러리를 설치합니다.\n",
    "- huggingface_hub는 Hugging Face에서 제공하는 모델, 데이터셋 등을 쉽게 액세스하고 사용할 수 있도록 도와주는 라이브러리입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814fe654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43997b16",
   "metadata": {},
   "source": [
    "- `HuggingFaceHubEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n",
    "- 이 클래스는 Hugging Face Hub에 호스팅된 임베딩 모델을 사용하여 텍스트를 벡터로 변환하는 기능을 제공합니다.\n",
    "- `HuggingFaceHubEmbeddings`는 LangChain 프레임워크에서 임베딩 기능을 확장하기 위해 커뮤니티에서 개발된 모듈입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e7e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceHubEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b278e",
   "metadata": {},
   "source": [
    "HuggingFaceHubEmbeddings 클래스를 사용하여 임베딩 객체를 생성합니다.\n",
    "\n",
    "- `HuggingFaceHubEmbeddings` 클래스는 Hugging Face Hub에 호스팅된 사전 훈련된 임베딩 모델을 사용하여 텍스트를 벡터로 변환합니다.\n",
    "- `embeddings` 변수에 `HuggingFaceHubEmbeddings` 클래스의 인스턴스를 할당합니다.\n",
    "- 이렇게 생성된 `embeddings` 객체는 텍스트 데이터를 벡터로 변환하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3e8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceHub에서 제공하는 임베딩 모델을 사용하여 임베딩 객체를 생성합니다.\n",
    "embeddings = HuggingFaceHubEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39fd3f",
   "metadata": {},
   "source": [
    "- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9937bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b755927",
   "metadata": {},
   "source": [
    "`embeddings.embed_query(text)`는 주어진 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n",
    "\n",
    "- `text` 매개변수로 전달된 텍스트를 임베딩 모델에 입력하여 벡터 표현을 생성합니다.\n",
    "- 생성된 임베딩 벡터는 `query_result` 변수에 저장됩니다.\n",
    "\n",
    "이 함수는 텍스트를 벡터 공간에 매핑하여 의미적 유사성을 계산하거나 검색에 활용할 수 있는 벡터 표현을 얻는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e95e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cca18c",
   "metadata": {},
   "source": [
    "임베딩된 차원을 수를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "184d5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원을 확인합니다.\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a24c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032299287617206573, -0.10691168159246445, -0.02121555432677269]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 결과의 처음 3개 항목을 선택합니다.\n",
    "query_result[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
