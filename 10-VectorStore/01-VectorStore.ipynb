{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/assets/images/vector_stores-125d1675d58cfb46ce9054c9019fea72.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 튜토리얼은 벡터 스토어와 관련된 기본 기능을 소개합니다. 벡터 스토어 작업의 핵심은 벡터 스토어에 넣을 벡터를 만드는 것이며, 이는 일반적으로 임베딩을 통해 만들어집니다. 따라서 이 작업을 시작하기 전에 텍스트 임베딩 모델 인터페이스에 익숙해지는 것이 좋습니다.\n",
    "\n",
    "훌륭한 벡터 저장소 옵션이 많이 있으며, 여기에는 무료 오픈 소스이며 로컬 컴퓨터에서 완전히 실행되는 몇 가지 옵션이 있습니다. 모든 통합을 검토하여 여러 가지 훌륭한 호스팅 서비스를 살펴보세요.\n",
    "\n",
    "**참고링크**\n",
    "\n",
    "- [LangChain 지원 VectorStore 리스트](https://python.langchain.com/docs/integrations/vectorstores/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① Chroma\n",
    "\n",
    "크로마는 오픈소스 벡터 데이터베이스입니다. Chroma는 Apache 2.0 라이선스가 부여됩니다.\n",
    "\n",
    "- [공식 도큐먼트](https://docs.trychroma.com/)\n",
    "- [홈페이지](https://www.trychroma.com/)\n",
    "\n",
    "**Apache 2.0 License 에 대해**\n",
    "\n",
    "Apache 2.0 라이선스는 오픈 소스 라이선스 중 하나로, **누구나 소프트웨어를 자유롭게 사용, 수정, 배포할 수 있도록 허용**하는 라이선스입니다.\n",
    "\n",
    "이 라이선스의 주요 특징은 다음과 같습니다:\n",
    "\n",
    "- 상업적 사용 가능: Apache 2.0 라이선스 하에 배포된 소프트웨어는 **상업적 목적을 포함하여 어떤 목적으로든 사용할 수 있습니다**. 이는 기업이나 개인이 이 라이선스로 된 소프트웨어를 상업적 제품이나 서비스에 통합하는 것을 가능하게 합니다.\n",
    "\n",
    "- 소스 코드 공개 의무 없음: 소프트웨어를 수정하거나 확장한 경우, 그 변경된 소스 코드를 공개할 의무가 없습니다. 하지만 원본 소프트웨어가 Apache 2.0 라이선스를 따른다면, 변경된 버전 역시 Apache 2.0 라이선스 하에 배포되어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지 무시\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# 텍스트를 600자 단위로 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "\n",
    "# TextLoader 를 통해 텍스트 파일을 로드\n",
    "split_docs = TextLoader(\"data/appendix-keywords.txt\").load_and_split(text_splitter)\n",
    "\n",
    "# Chroma 를 통해 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(split_docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`query` 에 질문을 담아서 `db` 에서 유사한 문장을 찾아냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(쿼리)\n",
    "similar_docs = chroma_db.similarity_search(\"TF IDF 에 대하여 알려줘\")\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 `OpenAIEmbeddings`을 사용하여 `query` 를 임베딩하고, `Chroma` 에서 유사도 검색을 수행한 결과입니다.\n",
    "\n",
    "이전에 수행한 코드와 결과는 동일합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n"
     ]
    }
   ],
   "source": [
    "# embedding_Vector 를 통해 유사도 검색\n",
    "embedding_vector = OpenAIEmbeddings().embed_query(\"TF IDF 에 대하여 알려줘\")\n",
    "similar_docs = chroma_db.similarity_search_by_vector(embedding_vector)\n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "\n",
      "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\n",
      "예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\n",
      "연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\n",
      "\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "\n",
      "Open Source\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(쿼리)\n",
    "similar_docs = chroma_db.similarity_search(\"Word2Vec 에 대하여 알려줘\")\n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorStoreRetriever: as_retreiver()\n",
    "\n",
    "`VectorStoreRetreiver` 는 벡터 저장소를 사용하여 문서를 검색하는 Retriever 입니다.\n",
    "\n",
    "이는 벡터 저장소 클래스를 경량 래퍼로 감싸서 리트리버 인터페이스를 따르도록 하는 것입니다.\n",
    "\n",
    "유사성 검색 및 MMR과 같이 벡터 저장소가 구현한 검색 방법을 사용하여 벡터 저장소의 텍스트를 쿼리합니다.\n",
    "\n",
    "생성된 VectorStore 에 as_retriever() 함수로 반환받습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 4\n",
      "[검색 결과]\n",
      "\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n"
     ]
    }
   ],
   "source": [
    "# retriever 생성\n",
    "retriever = chroma_db.as_retriever()\n",
    "\n",
    "# similarity_search 를 통해 유사도 높은 1개 문서를 검색\n",
    "relevant_docs = retriever.get_relevant_documents(\"VectorStore 에 대하여 알려줘\")\n",
    "\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 1\n",
      "[검색 결과]\n",
      "\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n"
     ]
    }
   ],
   "source": [
    "# retriever 생성\n",
    "retriever = chroma_db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# similarity_search 를 통해 유사도 높은 1개 문서를 검색\n",
    "relevant_docs = retriever.get_relevant_documents(\"VectorStore 에 대하여 알려줘\")\n",
    "\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `search_type`\n",
    "\n",
    "`search_type` 매개변수에 검색 알고리즘을 지정할 수 있습니다.\n",
    "\n",
    "- `similarity`(기본값), `mmr`, `similarity_score_threshold` 등의 옵션을 지정할 수 있습니다.\n",
    "- 아래에서 지정 옵션 별 차이에 대해 다룹니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`search_type='similarity'`**\n",
    "\n",
    "기본 값으로 설정되어 있습니다. vector store 의 유사도 알고리즘 기반으로 상위 K개의 문서를 검색합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n",
      "============================================================\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "relevant_docs = retriever.get_relevant_documents(\"VectorStore, TF IDF 에 대하여 알려줘\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Maximal Marginal Relevance(MMR) 검색`\n",
    "\n",
    "MMR은 쿼리와 관련된 항목을 검색하면서 동시에 내용의 중복을 최소화하는 기법입니다.\n",
    "\n",
    "이 방법은 단순히 관련성이 높은 항목들을 선택하는 대신, **관련성과 다양성 사이의 균형**을 찾는 데 중점을 둡니다.\n",
    "\n",
    "**MMR 에 대해 이해해보기**\n",
    "\n",
    "모임에 참석해 친구를 위해 새로운 사람들을 소개하는 상황을 상상해 보세요. 친구가 만나고 싶어하는 사람들의 특징(embedding vector)을 알고 있습니다.\n",
    "\n",
    "MMR 방식을 적용하면 다음과 같은 접근법을 사용합니다:\n",
    "\n",
    "1. 모임에 있는 모든 사람들의 프로필(list of embedding vector)을 살펴봅니다.\n",
    "2. 친구의 관심사와 특성에 부합하는 사람을 찾아 소개합니다.\n",
    "3. 그 후, 다시 참여한 사람들을 살펴보되, 이번에는 이미 소개한 사람과는 다른 특성을 가진 사람을 찾습니다.\n",
    "4. 여기서 lambda mult 매개변수는 친구의 취향과 새로운 특성 사이의 균형을 조정하는 역할을 합니다.\n",
    "5. 이 과정을 친구가 만나길 원하는 사람들의 수(k 매개변수)에 도달할 때까지 반복합니다.\n",
    "6. 마지막으로, 친구가 만난 사람들의 목록을 제공합니다.\n",
    "\n",
    "이 예시를 통해 MMR이 **관련성 높은 항목을 선택** 하는 동시에 **내용의 다양성을 유지** 하려는 방식을 이해할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`search_type='mmr'`** 을 통해 MMR 을 사용한 검색을 수행할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 11, updating n_results = 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n",
      "============================================================\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "relevant_docs = retriever.get_relevant_documents(\n",
    "    \"VectorStore, TF IDF 에 대하여 알려줘\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`search_type='similarity_score_threshold'`** 을 지정하면 `score_threshold` 기준을 충족하는 유사도 문서가 반환됩니다.\n",
    "\n",
    "만약 `{\"k\": 3}` 이지만, `{\"score_threshold\": 0.5}` 로 설정되었는데 score 가 0.5를 넘는 문서가 2개 밖에 없다면, 결과는 3개 문서가 아닌 2개 문서가 반환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n",
      "============================================================\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 2, \"score_threshold\": 0.5},\n",
    ")\n",
    "relevant_docs = retriever.get_relevant_documents(\n",
    "    \"VectorStore, TF IDF 에 대하여 알려줘\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `search_kwargs`\n",
    "\n",
    "search_kwargs에 다양한 옵션을 지정할 수 있습니다.\n",
    "\n",
    "다음의 `search_kwargs` 로 Retriever 의 검색 결과를 세부조정할 수 있습니다.\n",
    "\n",
    "- k: `\"k\"` 매개변수로 찾을 문서의 개수를 지정할 수 있습니다. 만약, `{\"k\": 3}` 지정한다면 3개의 유사도 높은 문서만 선택하겠다는 의미 입니다. 기본 값은 1입니다.\n",
    "- score_threshold: Minimum relevance threshold for `similarity_score_threshold`\n",
    "- fetch_k: Amount of documents to pass to `MMR` algorithm (Default: 20)\n",
    "- lambda_mult: Diversity of results returned by `MMR`. 1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
    "- filter: document를 메타데이터 기준으로 필터링 합니다. (예시) `search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\n",
      "예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\n",
      "연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\n",
      "예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\n",
      "연관키워드: 인공신경망, 머신러닝, 데이터 분석\n",
      "\n",
      "Schema\n",
      "\n",
      "정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\n",
      "예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\n",
      "연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\n",
      "\n",
      "DataFrame\n",
      "============================================================\n",
      "정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\n",
      "예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어 처리, 구문 분석\n",
      "\n",
      "VectorStore\n",
      "\n",
      "정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\n",
      "예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\n",
      "연관키워드: 임베딩, 데이터베이스, 벡터화\n",
      "\n",
      "SQL\n",
      "\n",
      "정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\n",
      "예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\n",
      "연관키워드: 데이터베이스, 쿼리, 데이터 관리\n",
      "\n",
      "CSV\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.75}\n",
    ")\n",
    "relevant_docs = retriever.get_relevant_documents(\n",
    "    \"VectorStore, TF IDF 에 대하여 알려줘\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② FAISS\n",
    "\n",
    "FAISS는 semantic search를 도와주는 Meta(구 Facebook)에서 만든 라이브러리 입니다.\n",
    "\n",
    "- 링크: https://github.com/facebookresearch/faiss\n",
    "\n",
    "리이선스는 **MIT License** 입니다.\n",
    "\n",
    "**[참고]**\n",
    "\n",
    "MIT 라이선스는 자유롭고 유연한 소프트웨어 라이선스 중 하나입니다. MIT 라이선스 하에 배포된 소프트웨어는 **상업적으로 이용** 할 수 있습니다\n",
    "\n",
    "주요 특징은 다음과 같습니다:\n",
    "\n",
    "- 간결함과 넓은 범위의 사용 허가: MIT 라이선스는 매우 간결하며, 사용자에게 소프트웨어를 거의 제한 없이 사용, 복사, 수정, 합병, 출판, 배포, 하위 라이선스 부여, 판매할 수 있는 권리를 부여합니다.\n",
    "\n",
    "- 저작권과 라이선스 고지 유지 요구: 라이선스는 사용자가 MIT 라이선스하에 배포된 모든 복사본과 상당한 부분에 원래의 저작권 고지와 이 라이선스 고지를 포함하도록 요구합니다.\n",
    "\n",
    "- 책임의 부인: MIT 라이선스는 소프트웨어가 '있는 그대로' 제공되며, 소프트웨어의 사용으로 인한 어떠한 보증도 제공하지 않습니다. 이는 소프트웨어 사용으로 인한 모든 위험은 사용자가 부담한다는 것을 의미합니다.\n",
    "\n",
    "MIT 라이선스는 그 간결함과 유연성으로 인해 많은 오픈 소스 프로젝트와 상업적 프로젝트에서 널리 사용됩니다. 이 라이선스는 소프트웨어 개발자가 자신의 소프트웨어를 거의 제한 없이 공유할 수 있도록 해주며, 소프트웨어 산업 전반에 걸쳐 협력과 혁신을 촉진하는 데 기여하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API 사용방법은 Chroma와 동일합니다. (동일한 인터페이스를 제공합니다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# TextSplitter 를 통해 텍스트를 500자 단위로 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# TextLoader 를 통해 텍스트 파일을 로드\n",
    "split_docs = TextLoader(\"data/appendix-keywords.txt\").load_and_split(text_splitter)\n",
    "# FAISS 를 통해 벡터 저장소 생성\n",
    "faiss_db = FAISS.from_documents(split_docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 4\n",
      "[검색 결과]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "\n",
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(쿼리)\n",
    "similar_docs = faiss_db.similarity_search(\"Embedding 에 대한 내용을 알려줘\")\n",
    "\n",
    "print(f\"문서의 개수: {len(similar_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(similar_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
